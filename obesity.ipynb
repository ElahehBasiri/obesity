{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  \n",
    "import pandas as pd  \n",
    "import matplotlib.pyplot as plt  \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import svm\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>family_history_with_overweight</th>\n",
       "      <th>FAVC</th>\n",
       "      <th>FCVC</th>\n",
       "      <th>NCP</th>\n",
       "      <th>CAEC</th>\n",
       "      <th>SMOKE</th>\n",
       "      <th>CH2O</th>\n",
       "      <th>SCC</th>\n",
       "      <th>FAF</th>\n",
       "      <th>TUE</th>\n",
       "      <th>CALC</th>\n",
       "      <th>MTRANS</th>\n",
       "      <th>NObeyesdad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Female</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>1.620000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>no</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>no</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Normal_Weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Female</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>1.520000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>yes</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>yes</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Normal_Weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Male</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>no</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Frequently</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Normal_Weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Male</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>no</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Frequently</td>\n",
       "      <td>Walking</td>\n",
       "      <td>Overweight_Level_I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Male</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1.780000</td>\n",
       "      <td>89.800000</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>no</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Overweight_Level_II</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2106</th>\n",
       "      <td>Female</td>\n",
       "      <td>20.976842</td>\n",
       "      <td>1.710730</td>\n",
       "      <td>131.408528</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>1.728139</td>\n",
       "      <td>no</td>\n",
       "      <td>1.676269</td>\n",
       "      <td>0.906247</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Obesity_Type_III</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2107</th>\n",
       "      <td>Female</td>\n",
       "      <td>21.982942</td>\n",
       "      <td>1.748584</td>\n",
       "      <td>133.742943</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.005130</td>\n",
       "      <td>no</td>\n",
       "      <td>1.341390</td>\n",
       "      <td>0.599270</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Obesity_Type_III</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2108</th>\n",
       "      <td>Female</td>\n",
       "      <td>22.524036</td>\n",
       "      <td>1.752206</td>\n",
       "      <td>133.689352</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.054193</td>\n",
       "      <td>no</td>\n",
       "      <td>1.414209</td>\n",
       "      <td>0.646288</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Obesity_Type_III</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2109</th>\n",
       "      <td>Female</td>\n",
       "      <td>24.361936</td>\n",
       "      <td>1.739450</td>\n",
       "      <td>133.346641</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.852339</td>\n",
       "      <td>no</td>\n",
       "      <td>1.139107</td>\n",
       "      <td>0.586035</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Obesity_Type_III</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2110</th>\n",
       "      <td>Female</td>\n",
       "      <td>23.664709</td>\n",
       "      <td>1.738836</td>\n",
       "      <td>133.472641</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.863513</td>\n",
       "      <td>no</td>\n",
       "      <td>1.026452</td>\n",
       "      <td>0.714137</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Obesity_Type_III</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2111 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Gender        Age    Height      Weight family_history_with_overweight  \\\n",
       "0     Female  21.000000  1.620000   64.000000                            yes   \n",
       "1     Female  21.000000  1.520000   56.000000                            yes   \n",
       "2       Male  23.000000  1.800000   77.000000                            yes   \n",
       "3       Male  27.000000  1.800000   87.000000                             no   \n",
       "4       Male  22.000000  1.780000   89.800000                             no   \n",
       "...      ...        ...       ...         ...                            ...   \n",
       "2106  Female  20.976842  1.710730  131.408528                            yes   \n",
       "2107  Female  21.982942  1.748584  133.742943                            yes   \n",
       "2108  Female  22.524036  1.752206  133.689352                            yes   \n",
       "2109  Female  24.361936  1.739450  133.346641                            yes   \n",
       "2110  Female  23.664709  1.738836  133.472641                            yes   \n",
       "\n",
       "     FAVC  FCVC  NCP       CAEC SMOKE      CH2O  SCC       FAF       TUE  \\\n",
       "0      no   2.0  3.0  Sometimes    no  2.000000   no  0.000000  1.000000   \n",
       "1      no   3.0  3.0  Sometimes   yes  3.000000  yes  3.000000  0.000000   \n",
       "2      no   2.0  3.0  Sometimes    no  2.000000   no  2.000000  1.000000   \n",
       "3      no   3.0  3.0  Sometimes    no  2.000000   no  2.000000  0.000000   \n",
       "4      no   2.0  1.0  Sometimes    no  2.000000   no  0.000000  0.000000   \n",
       "...   ...   ...  ...        ...   ...       ...  ...       ...       ...   \n",
       "2106  yes   3.0  3.0  Sometimes    no  1.728139   no  1.676269  0.906247   \n",
       "2107  yes   3.0  3.0  Sometimes    no  2.005130   no  1.341390  0.599270   \n",
       "2108  yes   3.0  3.0  Sometimes    no  2.054193   no  1.414209  0.646288   \n",
       "2109  yes   3.0  3.0  Sometimes    no  2.852339   no  1.139107  0.586035   \n",
       "2110  yes   3.0  3.0  Sometimes    no  2.863513   no  1.026452  0.714137   \n",
       "\n",
       "            CALC                 MTRANS           NObeyesdad  \n",
       "0             no  Public_Transportation        Normal_Weight  \n",
       "1      Sometimes  Public_Transportation        Normal_Weight  \n",
       "2     Frequently  Public_Transportation        Normal_Weight  \n",
       "3     Frequently                Walking   Overweight_Level_I  \n",
       "4      Sometimes  Public_Transportation  Overweight_Level_II  \n",
       "...          ...                    ...                  ...  \n",
       "2106   Sometimes  Public_Transportation     Obesity_Type_III  \n",
       "2107   Sometimes  Public_Transportation     Obesity_Type_III  \n",
       "2108   Sometimes  Public_Transportation     Obesity_Type_III  \n",
       "2109   Sometimes  Public_Transportation     Obesity_Type_III  \n",
       "2110   Sometimes  Public_Transportation     Obesity_Type_III  \n",
       "\n",
       "[2111 rows x 17 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"d:\\\\jupyter\\\\obesity\\\\ObesityDataSet_raw_and_data_sinthetic.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nulldf= df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2111, 17)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>family_history_with_overweight</th>\n",
       "      <th>FAVC</th>\n",
       "      <th>FCVC</th>\n",
       "      <th>NCP</th>\n",
       "      <th>CAEC</th>\n",
       "      <th>SMOKE</th>\n",
       "      <th>CH2O</th>\n",
       "      <th>SCC</th>\n",
       "      <th>FAF</th>\n",
       "      <th>TUE</th>\n",
       "      <th>CALC</th>\n",
       "      <th>MTRANS</th>\n",
       "      <th>NObeyesdad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.62</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>170</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>840</td>\n",
       "      <td>no</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.52</td>\n",
       "      <td>56.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>809</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>77.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>170</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>840</td>\n",
       "      <td>Frequently</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>809</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Frequently</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.78</td>\n",
       "      <td>89.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>170</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1.62</td>\n",
       "      <td>53.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>170</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.50</td>\n",
       "      <td>55.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>809</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.64</td>\n",
       "      <td>53.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>170</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.78</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>809</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>840</td>\n",
       "      <td>Frequently</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.72</td>\n",
       "      <td>68.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>170</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>840</td>\n",
       "      <td>no</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gender   Age  Height  Weight  family_history_with_overweight  FAVC  FCVC  \\\n",
       "0       0  21.0    1.62    64.0                               1     0   170   \n",
       "1       0  21.0    1.52    56.0                               1     0   809   \n",
       "2       1  23.0    1.80    77.0                               1     0   170   \n",
       "3       1  27.0    1.80    87.0                               0     0   809   \n",
       "4       1  22.0    1.78    89.8                               0     0   170   \n",
       "5       1  29.0    1.62    53.0                               0     1   170   \n",
       "6       0  23.0    1.50    55.0                               1     1   809   \n",
       "7       1  22.0    1.64    53.0                               0     0   170   \n",
       "8       1  24.0    1.78    64.0                               1     1   809   \n",
       "9       1  22.0    1.72    68.0                               1     1   170   \n",
       "\n",
       "   NCP  CAEC  SMOKE  CH2O  SCC  FAF  TUE        CALC  MTRANS  NObeyesdad  \n",
       "0  3.0     2      0   2.0    0  0.0  840          no       3           1  \n",
       "1  3.0     2      1   3.0    1  3.0    0   Sometimes       3           1  \n",
       "2  3.0     2      0   2.0    0  2.0  840  Frequently       3           1  \n",
       "3  3.0     2      0   2.0    0  2.0    0  Frequently       4           5  \n",
       "4  1.0     2      0   2.0    0  0.0    0   Sometimes       3           6  \n",
       "5  3.0     2      0   2.0    0  0.0    0   Sometimes       0           1  \n",
       "6  3.0     2      0   2.0    0  1.0    0   Sometimes       2           1  \n",
       "7  3.0     2      0   2.0    0  3.0    0   Sometimes       3           1  \n",
       "8  3.0     2      0   2.0    0  1.0  840  Frequently       3           1  \n",
       "9  3.0     2      0   2.0    0  1.0  840          no       3           1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gender                              int64\n",
       "Age                               float64\n",
       "Height                            float64\n",
       "Weight                            float64\n",
       "family_history_with_overweight      int64\n",
       "FAVC                                int64\n",
       "FCVC                                int64\n",
       "NCP                               float64\n",
       "CAEC                                int64\n",
       "SMOKE                               int64\n",
       "CH2O                              float64\n",
       "SCC                                 int64\n",
       "FAF                               float64\n",
       "TUE                                 int64\n",
       "CALC                               object\n",
       "MTRANS                              int64\n",
       "NObeyesdad                          int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NObeyesdad\n",
       "0    272\n",
       "1    287\n",
       "2    351\n",
       "3    297\n",
       "4    324\n",
       "5    290\n",
       "6    290\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('NObeyesdad').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Frequency'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkQAAAGdCAYAAADzOWwgAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB1J0lEQVR4nO3deVxO6f8/8Nfdrl1oIxVtlpJd1rKVMQyyJRRhZmSJLGNsYcgy9n1Mm6+dwZjMGImyZQnZlxCZURjULbSo8/vDr/NxK1Sq+879ej4e5/HoXOc613lfh+773XWuc45EEAQBREREREpMRd4BEBEREckbEyIiIiJSekyIiIiISOkxISIiIiKlx4SIiIiIlB4TIiIiIlJ6TIiIiIhI6TEhIiIiIqWnJu8AKoK8vDw8fPgQenp6kEgk8g6HiIiIikAQBLx48QLm5uZQUfn4GBAToiJ4+PAhLCws5B0GERERlcCDBw9Qo0aNj9ZhQlQEenp6AN6eUH19fTlHQ0REREUhlUphYWEhfo9/DBOiIsi/TKavr8+EiIiIqIIpynQXTqomIiIipceEiIiIiJQeEyIiIiJSepxDREpHEAS8efMGubm58g6FiBSUqqoq1NTU+KgVJcKEiJRKdnY2UlJS8OrVK3mHQkQKTltbG2ZmZtDQ0JB3KFQOmBCR0sjLy0NSUhJUVVVhbm4ODQ0N/vVHRAUIgoDs7Gw8efIESUlJsLW1/eRD/ajiY0JESiM7Oxt5eXmwsLCAtra2vMMhIgVWqVIlqKur4/79+8jOzoaWlpa8Q6IyxpSXlA7/0iOiouBnhXLhvzYREREpPSZEREREpPQ4h4iUntUP+8v1ePfmdy3X45UGV1dXODs7Y9myZfIOhYioTHCEiKiCSE1NxdixY2FjYwMtLS2YmJigVatWWLt2LR8jQET0mThCRFQB3L17F61atYKhoSHmzZsHR0dHaGpq4vLly/jll19QvXp1dO/eXd5hflBubi4kEgknqRKRwuKnE1EFMHLkSKipqSE+Ph59+/ZFnTp1UKtWLXzzzTfYv38/unXrBgBIS0vDsGHDUK1aNejr66N9+/a4ePGi2E5QUBCcnZ3xf//3f7CysoKBgQH69++PFy9eiHVevnyJwYMHQ1dXF2ZmZli8eHGBeLKysjBhwgRUr14dOjo6aN68OWJiYsTt4eHhMDQ0xL59+1C3bl1oamoiOTm57E4QEdFn4giRAljc72t5h1Bsgdsj5R2C0nj69CkOHjyIefPmQUdHp9A6+Q+Y7NOnDypVqoS//voLBgYGWL9+PTp06IBbt27ByMgIAHDnzh3s3bsXkZGReP78Ofr27Yv58+dj7ty5AICJEyciNjYWv//+O4yNjfHjjz/i/PnzcHZ2Fo83atQoXLt2Ddu2bYO5uTn27NkDDw8PXL58Gba2tgCAV69eYcGCBfj1119RpUoVGBsbl+FZIiL6PEyIiBTc7du3IQgC7O3tZcqrVq2KzMxMAIC/vz+6deuGM2fO4PHjx9DU1AQA/Pzzz9i7dy927dqFESNGAHj7xO7w8HDo6ekBAAYNGoTo6GjMnTsXGRkZCAkJwaZNm9ChQwcAQEREBGrUqCEeNzk5GWFhYUhOToa5uTkAYMKECThw4ADCwsIwb948AEBOTg7WrFmDBg0alOHZISIqHUyIiCqoM2fOIC8vD97e3sjKysLFixeRkZGBKlWqyNR7/fo17ty5I65bWVmJyRAAmJmZ4fHjxwDejh5lZ2ejefPm4nYjIyOZZOzy5cvIzc2FnZ2dzHGysrJkjq2hoQEnJ6fS6SwRURljQkSk4GxsbCCRSHDz5k2Z8lq1agF4+4oBAMjIyICZmZnMXJ58hoaG4s/q6uoy2yQSCfLy8oocT0ZGBlRVVXHu3DmoqqrKbNPV1RV/rlSpEt8VR0QVBhMiIgVXpUoVdOrUCatWrcLo0aM/OI+oUaNGSE1NhZqaGqysrEp0rNq1a0NdXR2nT59GzZo1AQDPnz/HrVu30K5dOwBAw4YNkZubi8ePH6NNmzYlOg4RkaLhXWZEFcCaNWvw5s0bNGnSBNu3b8f169dx8+ZNbNq0CTdu3ICqqio6duwIFxcX9OjRAwcPHsS9e/dw8uRJTJ06FfHx8UU6jq6uLvz8/DBx4kQcPnwYV65cga+vr8zt8nZ2dvD29sbgwYOxe/duJCUl4cyZMwgODsb+/eX7kEsiotLCESJSehXhydG1a9fGhQsXMG/ePEyZMgX//PMPNDU1UbduXUyYMAEjR46ERCLBn3/+ialTp2LIkCF48uQJTE1N0bZtW5iYmBT5WIsWLUJGRga6desGPT09BAYGIj09XaZOWFgYfvrpJwQGBuLff/9F1apV0aJFC3z9dcW7Y5KICAAkgiAI8g5C0UmlUhgYGCA9PR36+vql3j5vuy8fmZmZSEpKgrW1NbS0tOQdDhEpOH5mVHzF+f7mJTMiIiJSekyIiIiISOkxISIiIiKlx4SIiIiIlB4TIiIiIlJ6TIiIiIhI6TEhIiIiIqUn14QoODgYTZs2hZ6eHoyNjdGjR48C72vKzMyEv78/qlSpAl1dXXh6euLRo0cydZKTk9G1a1doa2vD2NgYEydOxJs3b2TqxMTEoFGjRtDU1ISNjQ3Cw8PLuntERERUQcg1IYqNjYW/vz9OnTqFqKgo5OTkoHPnznj58qVYZ9y4cfjjjz+wc+dOxMbG4uHDh+jVq5e4PTc3F127dkV2djZOnjyJiIgIhIeHY8aMGWKdpKQkdO3aFW5ubkhISEBAQACGDRuGv//+u1z7S0RERIpJoZ5U/eTJExgbGyM2NhZt27ZFeno6qlWrhi1btqB3794AgBs3bqBOnTqIi4tDixYt8Ndff+Hrr7/Gw4cPxdcTrFu3DpMnT8aTJ0+goaGByZMnY//+/bhy5Yp4rP79+yMtLQ0HDhz4ZFx8UnVBX9STqoMMyjeQoPRP1ylEXFwcWrduDQ8PD74zjKgc8EnVFV+FfVJ1/vuSjIyMAADnzp1DTk4OOnbsKNZxcHBAzZo1ERcXB+Dtl4Sjo6PMu5rc3d0hlUpx9epVsc67beTXyW/jfVlZWZBKpTILkbyFhIRg9OjROHr0KB4+fCjvcIiIvigKkxDl5eUhICAArVq1Qv369QEAqamp0NDQgKGhoUxdExMTpKaminXef3Fl/vqn6kilUrx+/bpALMHBwTAwMBAXCwuLUukjUUllZGRg+/bt+P7779G1a9cCc+D27dsHW1tbaGlpwc3NDREREZBIJEhLSxPrHD9+HG3atEGlSpVgYWGBMWPGyFyeJiJSZgqTEPn7++PKlSvYtm2bvEPBlClTkJ6eLi4PHjyQd0ik5Hbs2AEHBwfY29tj4MCBCA0NRf7V7qSkJPTu3Rs9evTAxYsX8e2332Lq1Kky+9+5cwceHh7w9PTEpUuXsH37dhw/fhyjRo2SR3eIiBSOQiREo0aNQmRkJI4cOYIaNWqI5aampsjOzpb5KxcAHj16BFNTU7HO+3ed5a9/qo6+vj4qVapUIB5NTU3o6+vLLETyFBISgoEDBwIAPDw8kJ6ejtjYWADA+vXrYW9vj0WLFsHe3h79+/eHr6+vzP7BwcHw9vZGQEAAbG1t0bJlS6xYsQIbN25EZmZmeXeHiEjhyDUhEgQBo0aNwp49e3D48GFYW1vLbG/cuDHU1dURHR0tlt28eRPJyclwcXEBALi4uODy5ct4/PixWCcqKgr6+vqoW7euWOfdNvLr5LdBpMhu3ryJM2fOwMvLCwCgpqaGfv36ISQkRNzetGlTmX2aNWsms37x4kWEh4dDV1dXXNzd3ZGXl4ekpKTy6QgRkQJTk+fB/f39sWXLFvz+++/Q09MT5/wYGBigUqVKMDAwgJ+fH8aPHw8jIyPo6+tj9OjRcHFxQYsWLQAAnTt3Rt26dTFo0CAsXLgQqampmDZtGvz9/aGpqQkA+O6777Bq1SpMmjQJQ4cOxeHDh7Fjxw7eqUMVQkhICN68eQNzc3OxTBAEaGpqYtWqVUVqIyMjA99++y3GjBlTYFvNmjVLLVYioopKrgnR2rVrAQCurq4y5WFhYeKQ/9KlS6GiogJPT09kZWXB3d0da9asEeuqqqoiMjIS33//PVxcXKCjowMfHx/Mnj1brGNtbY39+/dj3LhxWL58OWrUqIFff/0V7u7uZd5Hos/x5s0bbNy4EYsXL0bnzp1ltvXo0QNbt26Fvb09/vzzT5ltZ8+elVlv1KgRrl27BhsbmzKPmYioIpJrQlSURyBpaWlh9erVWL169QfrWFpaFvhCeJ+rqysuXLhQ7BiJ5CkyMhLPnz+Hn58fDAxkn5fk6emJkJAQ7NixA0uWLMHkyZPh5+eHhIQE8S40iUQCAJg8eTJatGiBUaNGYdiwYdDR0cG1a9cQFRVV5FEmIqIvmUJMqiaiwoWEhKBjx44FkiHgbUIUHx+PFy9eYNeuXdi9ezecnJywdu1a8S6z/MvGTk5OiI2Nxa1bt9CmTRs0bNgQM2bMkLkMR0SkzOQ6QkSkEEr45Ojy8Mcff3xwW7NmzcRRVicnJ3Tv3l3cNnfuXNSoUUPm6bpNmzbFwYMHyy5YIqIKjAkR0RdgzZo1aNq0KapUqYITJ05g0aJFfMYQEVExMCEi+gIkJibip59+wrNnz1CzZk0EBgZiypQp8g6LiKjCYEJE9AVYunQpli5dKu8wiIgqLE6qJiIiIqXHhIiIiIiUHhMiIiIiUnpMiIiIiEjpMSEiIiIipceEiIiIiJQeEyIiJWJlZYVly5YVuf69e/cgkUiQkJBQZjERESkCPoeIlJ5jhGO5Hu+yz+Vi7+Pr64u0tDTs3btXpjwmJgZubm54/vw5DA0NP9nO2bNnoaOjU+zjf0x4eDgCAgKQlpZWqu0SEZUnJkRESqRatWryDoGISCHxkhnRF+T48eNo06YNKlWqBAsLC4wZMwYvX74Ut79/yezGjRto3bo1tLS0ULduXRw6dAgSiaTASNTdu3fh5uYGbW1tNGjQAHFxcQDejlANGTIE6enpkEgkkEgkCAoKKoeeEhGVLiZERF+IO3fuwMPDA56enrh06RK2b9+O48ePf/Alr7m5uejRowe0tbVx+vRp/PLLL5g6dWqhdadOnYoJEyYgISEBdnZ28PLywps3b9CyZUssW7YM+vr6SElJQUpKCiZMmFCW3SQiKhO8ZEZUQURGRkJXV1emLDc3V/w5ODgY3t7eCAgIAADY2tpixYoVaNeuHdauXQstLS2ZfaOionDnzh3ExMTA1NQUADB37lx06tSpwLEnTJiArl27AgBmzZqFevXq4fbt23BwcICBgQEkEonYBhFRRcSEiKiCcHNzw9q1a2XKTp8+jYEDBwIALl68iEuXLmHz5s3idkEQkJeXh6SkJNSpU0dm35s3b8LCwkImkWnWrFmhx3ZychJ/NjMzAwA8fvwYDg4On9cpIiIFwYSIqILQ0dGBjY2NTNk///wj/pyRkYFvv/0WY8aMKbBvzZo1P+vY6urq4s8SiQQAkJeX91ltEhEpEiZERF+IRo0a4dq1awWSpg+xt7fHgwcP8OjRI5iYmAB4e1t+cWloaMhcuiMiqog4qZroCzF58mScPHkSo0aNQkJCAhITE/H7779/cFJ1p06dULt2bfj4+ODSpUs4ceIEpk2bBuB/o0BFYWVlhYyMDERHR+O///7Dq1evSqU/RETliQkR0RfCyckJsbGxuHXrFtq0aYOGDRtixowZMDc3L7S+qqoq9u7di4yMDDRt2hTDhg0T7zJ7fwL2x7Rs2RLfffcd+vXrh2rVqmHhwoWl0h8iovIkEQRBkHcQik4qlcLAwADp6enQ19cv9fYX9/u61Nssa4HbI+UdQrFlZmYiKSkJ1tbWxfrCVyYnTpxA69atcfv2bdSuXVve4RDJFT8zKr7ifH9zDhGREtuzZw90dXVha2uL27dvY+zYsWjVqhWTISJSOkyIiJTYixcvMHnyZCQnJ6Nq1aro2LEjFi9eLO+wiIjKHRMiIiU2ePBgDB48WN5hEBHJHSdVExERkdJjQkRERERKjwkRERERKT0mRERERKT05JoQHT16FN26dYO5uTkkEgn27t0rs10ikRS6LFq0SKxjZWVVYPv8+fNl2rl06RLatGkDLS0tWFhY8MFxREREJEOuCdHLly/RoEEDrF69utDtKSkpMktoaCgkEgk8PT1l6s2ePVum3ujRo8VtUqkUnTt3hqWlJc6dO4dFixYhKCgIv/zyS5n2jYiIiCoOud5236VLF3Tp0uWD201NTWXWf//9d7i5uaFWrVoy5Xp6egXq5tu8eTOys7MRGhoKDQ0N1KtXDwkJCViyZAlGjBjx+Z0gqoBiYmLg5uaG58+fw9DQsEj7BAUFYe/evUhISCjT2IiI5KHCPIfo0aNH2L9/PyIiIgpsmz9/PubMmYOaNWtiwIABGDduHNTU3nYtLi4Obdu2hYaGhljf3d0dCxYswPPnz1G5cuUC7WVlZSErK0tcl0qlZdAjUhTXHeqU6/Hq3LherPrr1q3DxIkT8fz5c/H/dUZGBipXroxWrVohJiZGrJuf6Hzq1RstW7ZESkoKDAwMStSHD3F1dYWzszOWLVtWqu0SEZW1CjOpOiIiAnp6eujVq5dM+ZgxY7Bt2zYcOXIE3377LebNm4dJkyaJ21NTU2FiYiKzT/56ampqoccKDg6GgYGBuFhYWJRyb4iKzs3NDRkZGYiPjxfLjh07BlNTU5w+fRqZmZli+ZEjR1CzZs1PvnpDQ0MDpqamxXqrPRHRl6zCJEShoaHw9vYu8IK98ePHw9XVFU5OTvjuu++wePFirFy5UmaEp7imTJmC9PR0cXnw4MHnhk9UYvb29jAzMyswEvTNN9/A2toap06dkil3c3NDXl4egoODYW1tjUqVKqFBgwbYtWuXTD2JRIK0tDSxbMOGDbCwsIC2tjZ69uyJJUuWFHo57f/+7/9gZWUFAwMD9O/fHy9evAAA+Pr6IjY2FsuXLxdvcLh3715pnw4iojJRIRKiY8eO4ebNmxg2bNgn6zZv3hxv3rwRP4hNTU3x6NEjmTr56x+ad6SpqQl9fX2ZhUie3NzccOTIEXH9yJEjcHV1Rbt27cTy169f4/Tp03Bzc0NwcDA2btyIdevW4erVqxg3bhwGDhyI2NjYQts/ceIEvvvuO4wdOxYJCQno1KkT5s6dW6DenTt3sHfvXkRGRiIyMhKxsbHiXZ3Lly+Hi4sLhg8fLt7gwNFVIqooKsQcopCQEDRu3BgNGjT4ZN2EhASoqKjA2NgYAODi4oKpU6ciJycH6urqAICoqCjY29sXOn+ISBG5ubkhICAAb968wevXr3HhwgW0a9cOOTk5WLduHYC38+WysrLg6uqKunXr4tChQ3BxcQEA1KpVC8ePH8f69evRrl27Au2vXLkSXbp0wYQJEwAAdnZ2OHnyJCIjI2Xq5eXlITw8HHp6egCAQYMGITo6GnPnzoWBgQE0NDSgra39wT82iIgUlVxHiDIyMpCQkCDetZKUlISEhAQkJyeLdaRSKXbu3Fno6FBcXByWLVuGixcv4u7du9i8ebP4l3B+sjNgwABoaGjAz88PV69exfbt27F8+XKMHz++XPpIVBpcXV3x8uVLnD17FseOHYOdnR2qVauGdu3aifOIYmJiUKtWLWRkZODVq1fo1KkTdHV1xWXjxo24c+dOoe3fvHkTzZo1kyl7fx14+9yv/GQIAMzMzPD48ePS7SwRkRzIdYQoPj4ebm5u4np+kuLj44Pw8HAAwLZt2yAIAry8vArsr6mpiW3btiEoKAhZWVmwtrbGuHHjZJIdAwMDHDx4EP7+/mjcuDGqVq2KGTNm8JZ7qlBsbGxQo0YNHDlyBM+fPxdHeczNzWFhYYGTJ0/iyJEjaN++PTIyMgAA+/fvR/Xq1WXa0dTU/Kw48kdZ80kkEuTl5X1Wm0REikCuCZGrqysEQfhonREjRnwweWnUqJHMhNIPcXJywrFjx0oUI5GicHNzQ0xMDJ4/f46JEyeK5W3btsVff/2FM2fO4Pvvv0fdunWhqamJ5OTkQi+PFcbe3h5nz56VKXt/vSg0NDSQm5tb7P2IiOStQswhIqK3CZG/vz9ycnJkEp127dph1KhRyM7OhpubG/T09DBhwgSMGzcOeXl5aN26NdLT03HixAno6+vDx8enQNujR49G27ZtsWTJEnTr1g2HDx/GX3/9Vezb8q2srHD69Gncu3cPurq6MDIygopKhbh3g4iUHD+piCoINzc3vH79GjY2NjLP1mrXrh1evHgh3p4PAHPmzMH06dMRHByMOnXqwMPDA/v374e1tXWhbbdq1Qrr1q3DkiVL0KBBAxw4cADjxo0r8JiLT5kwYQJUVVVRt25dVKtWTWY+IBGRIpMIn7pmRZBKpTAwMEB6enqZ3IK/uN/Xpd5mWQvcHvnpSgomMzMTSUlJsLa2LvYXvTIaPnw4bty4wcvNpLT4mVHxFef7m5fMiAgA8PPPP6NTp07Q0dHBX3/9hYiICKxZs0beYRERlQsmREQEADhz5gwWLlyIFy9eoFatWlixYkWRHoZKRPQlYEJERACAHTt2yDsEIiK54aRqIiIiUnpMiIiIiEjpMSEiIiIipceEiIiIiJQeEyIiIiJSekyIiIiISOkxISKqAARBwIgRI2BkZASJRIKEhIQyOY6vry969Oghrru6uiIgIKBM2i6MlZUVli1bVirHU1RBQUFwdnb+aJ179+6V6b9zRVKU8/W+0vx/S8qDzyEipbf6u8Plejz/de2Lvc+BAwcQHh6OmJgY1KpVC1WrVi2DyIDly5dDnm/zOXv2LHR0dIpU18rKCgEBARXui2/ChAkYPXq0uO7r64u0tDTs3btXfkEpsPfPV2mRSCTYs2fPJ5N0Uh5MiIgqgDt37sDMzAwtW7Ys0+MYGBiUafufUq1atXI/ZnZ2NjQ0NMrteLq6utDV1S2345WnnJwcqKurl2qbX/L5IsXCS2ZECs7X1xejR49GcnIyJBIJrKyscODAAbRu3RqGhoaoUqUKvv76a9y5c0fcJ/+Sy44dO9CmTRtUqlQJTZs2xa1bt3D27Fk0adIEurq66NKlC548eSJzrA/9xTx79mzUr1+/QLmzszOmT59e5P78/PPPMDMzQ5UqVeDv74+cnBxx27uXzARBQFBQEGrWrAlNTU2Ym5tjzJgxAN5eErl//z7GjRsHiUQCiUQitvHbb7+hXr160NTUhJWVFRYvXixzfCsrK8yZMweDBw+Gvr4+RowYgfbt22PUqFEy9Z48eQINDQ1ER0d/tD+rVq2SOS979+6FRCLBunXrxLKOHTti2rRpAGQvAQUFBSEiIgK///672I+YmBhxv7t378LNzQ3a2tpo0KAB4uLiPnF2/+dj5+HHH39E8+bNC+zToEEDzJ49W1z/9ddfUadOHWhpacHBwUHm3Xb5/8e2b9+Odu3aQUtLC5s2bUK1atWwa9cusZ6zszPMzMzE9ePHj0NTUxOvXr0CAKSlpWHYsGGoVq0a9PX10b59e1y8eFGs//4lszdv3mDMmDHi//3JkyfDx8enwP/bvLw8TJo0CUZGRjA1NUVQUJC4zcrKCgDQs2dP8XeKiAkRkYJbvnw5Zs+ejRo1aiAlJQVnz57Fy5cvMX78eMTHxyM6OhoqKiro2bMn8vLyZPadOXMmpk2bhvPnz0NNTQ0DBgzApEmTsHz5chw7dgy3b9/GjBkzihTH0KFDcf36dZw9e1Ysu3DhAi5duoQhQ4YUqY0jR47gzp07OHLkCCIiIhAeHo7w8PBC6/72229YunQp1q9fj8TEROzduxeOjo4AgN27d6NGjRqYPXs2UlJSkJKSAgA4d+4c+vbti/79++Py5csICgrC9OnTCxzj559/RoMGDXDhwgVMnz4dw4YNw5YtW5CVlSXW2bRpE6pXr4727T9+ibNdu3a4du2amFjGxsaiatWqYmKTk5ODuLg4uLq6Fth3woQJ6Nu3Lzw8PMR+vDsKOHXqVEyYMAEJCQmws7ODl5cX3rx589F4inIevL29cebMGZkk+urVq7h06RIGDBgAANi8eTNmzJiBuXPn4vr165g3bx6mT5+OiIgImWP98MMPGDt2LK5fvw4PDw+0bdtW7Pvz589x/fp1vH79Gjdu3BDPT9OmTaGtrQ0A6NOnDx4/foy//voL586dQ6NGjdChQwc8e/as0L4tWLAAmzdvRlhYGE6cOAGpVFro5caIiAjo6Ojg9OnTWLhwIWbPno2oqCgAEP8Ph4WFib9TRLxkRqTgDAwMoKenB1VVVZiamgIAPD09ZeqEhoaiWrVquHbtmsxoxYQJE+Du7g4AGDt2LLy8vBAdHY1WrVoBAPz8/D6YkLyvRo0acHd3R1hYGJo2bQrg7RdKu3btUKtWrSK1UblyZaxatQqqqqpwcHBA165dER0djeHDhxeom5ycDFNTU3Ts2BHq6uqoWbMmmjVrBgAwMjKCqqoq9PT0xHMCAEuWLEGHDh3EESs7Oztcu3YNixYtgq+vr1ivffv2CAwMFNerV6+OUaNG4ffff0ffvn0BAOHh4fD19ZUZfSpM/fr1YWRkhNjYWPTu3RsxMTEIDAzE8uXLAbx9aW5OTk6hlzt1dXVRqVIlZGVlyfQj34QJE9C1a1cAwKxZs1CvXj3cvn0bDg4OH43pU+ehXr16aNCgAbZs2SLW2bx5M5o3bw4bGxsAb5PpxYsXo1evXgAAa2trXLt2DevXr4ePj494rICAALEO8Hb0bv369QCAo0ePomHDhjA1NUVMTAwcHBwQExODdu3aAXg7WnTmzBk8fvwYmpqaAN4mq3v37sWuXbswYsSIAn1buXIlpkyZgp49ewJ4O0L3559/Fqjn5OSEmTNnAgBsbW2xatUqREdHo1OnTuKlWUNDw0LPOyknjhARVUCJiYnw8vJCrVq1oK+vLw75Jycny9RzcnISfzYxMQEAcZQlv+zx48dFPu7w4cOxdetWZGZmIjs7G1u2bMHQoUOLvH+9evWgqqoqrpuZmX3w+H369MHr169Rq1YtDB8+HHv27Pnk6Mj169fFZC9fq1atkJiYiNzcXLGsSZMmMnW0tLQwaNAghIaGAgDOnz+PK1euyCRRHyKRSMRRkbS0NFy7dg0jR45EVlYWbty4UWBEpDje/ffLv+xUlH+vopwHb29vbNmyBcDby5Nbt26Ft7c3AODly5e4c+cO/Pz8xDk8urq6+Omnn2RGlYCC5/LdEbPY2Fi4urrC1dUVMTExyMnJwcmTJ8XRsosXLyIjIwNVqlSROU5SUlKB4wBAeno6Hj16JCbGAKCqqorGjRt/9Nzln7/i/F8n5cMRIqIKqFu3brC0tMSGDRtgbm6OvLw81K9fH9nZ2TL13p3gmj/S8X7Z+5fZPnVcTU1N7NmzBxoaGsjJyUHv3r2LvP/7E24/dnwLCwvcvHkThw4dQlRUFEaOHIlFixYhNjb2syfuFnYn27Bhw+Ds7Ix//vkHYWFhaN++PSwtLYvUnqurK3755RccO3YMDRs2hL6+vpgkxcbGiiMixVXYv19x/r0+xsvLC5MnT8b58+fx+vVrPHjwAP369QMAZGRkAAA2bNhQYK7RuwktUPBcOjo6iiNmsbGxmDt3LkxNTbFgwQKcPXtWZrQsIyMDZmZmMvOm8hkaGn5W/4rzf40IYEJEVOE8ffoUN2/exIYNG9CmTRsAby89lAc1NTX4+PggLCwMGhoa6N+/PypVqlRmx6tUqRK6deuGbt26wd/fHw4ODrh8+TIaNWoEDQ0NmVEfAKhTpw5OnDghU3bixAnY2dkV+CJ/n6OjI5o0aYINGzZgy5YtWLVqVZHjbNeuHQICArBz505x9MPV1RWHDh3CiRMnZC7Pva+wfnyuopyHGjVqoF27dti8eTNev36NTp06wdjYGMDbkUNzc3PcvXtXHDUqKolEgjZt2uD333/H1atX0bp1a2hrayMrKwvr169HkyZNxCSqUaNGSE1NhZqaWpEmNhsYGMDExARnz55F27ZtAQC5ubk4f/58sZ9VpK6uXurnnSo2JkREFUzlypVRpUoV/PLLLzAzM0NycjJ++OGHcjv+sGHDUKdOHQAo8KVbmsLDw5Gbm4vmzZtDW1sbmzZtQqVKlcRRGysrKxw9ehT9+/eHpqYmqlatisDAQDRt2hRz5sxBv379EBcXh1WrVsncHfWpvo0aNQo6OjriHJWicHJyQuXKlbFlyxZERkYCeJsQTZgwARKJpMDlq3dZWVnh77//xs2bN1GlSpVSefRBUc+Dt7c3Zs6ciezsbCxdulRm26xZszBmzBgYGBjAw8MDWVlZiI+Px/PnzzF+/PiPHt/V1RWBgYHi3YwA0LZtW2zevBkTJ04U63Xs2BEuLi7o0aMHFi5cCDs7Ozx8+BD79+9Hz549C1yOA4DRo0cjODgYNjY2cHBwwMqVK/H8+fNPzvV6n5WVlTifTlNTE5UrVy7W/vTl4RwiogpGRUUF27Ztw7lz51C/fn2MGzcOixYtKrfj29raomXLlnBwcCj01u3SYmhoiA0bNqBVq1ZwcnLCoUOH8Mcff6BKlSoA3j4G4N69e6hdu7Y4SbZRo0bYsWMHtm3bhvr162PGjBmYPXt2keYCAW8vI6mpqcHLywtaWlpFjjV/VEQikaB169YA3iZJ+vr6MiMihRk+fDjs7e3RpEkTVKtWrVSSzKKeh969e+Pp06d49epVgdvWhw0bhl9//RVhYWFwdHREu3btEB4eDmtr608ev127dsjNzZW5s87V1bVAmUQiwZ9//om2bdtiyJAhsLOzQ//+/XH//n1xztv7Jk+eDC8vLwwePBguLi7Q1dWFu7t7sf69AGDx4sWIioqChYUFGjZsWKx96cskEeT5WNoKQiqVwsDAAOnp6dDX1y/19hf3+7rU2yxrgdsj5R1CsWVmZiIpKQnW1tbF/vCk/xEEAba2thg5cuQnRwoqmvwE6+zZs2jUqJG8w6EiyMvLQ506ddC3b1/MmTOnVNvmZ0bFV5zvb14yI6Iie/LkCbZt24bU1NQiP3uoIsjJycHTp08xbdo0tGjRgsmQArt//z4OHjyIdu3aISsrC6tWrUJSUpL4/CSikuIlMyIqMmNjY8yePRu//PJLgTkX7942/f5y7NgxOUVcNCdOnICZmRnOnj0r84RpADh27NhH+yYPXbp0+WA88+bNk0tM5UVFRQXh4eFo2rQpWrVqhcuXL+PQoUPivDaikuIIEREV2ceusH/szezVq1cvg2hKj6ur6wf71qRJE4V76/yvv/6K169fF7rNyMionKMpXxYWFmU6mZ+UFxMiIioV+U84/tJUqlRJ4fqm6AkmUUXES2ZERESk9JgQERERkdJjQkRERERKT64J0dGjR9GtWzeYm5tDIpFg7969Mtvz3zT97uLh4SFT59mzZ/D29oa+vj4MDQ3h5+cnvocn36VLl9CmTRtoaWnBwsICCxcuLOuuERERUQUi14To5cuXaNCgAVavXv3BOh4eHkhJSRGXrVu3ymz39vbG1atXERUVhcjISBw9ehQjRowQt0ulUnTu3BmWlpY4d+4cFi1ahKCgIPzyyy9l1i8iIiKqWOR6l1mXLl3QpUuXj9bR1NSEqalpoduuX7+OAwcO4OzZs+I7b1auXImvvvoKP//8M8zNzbF582ZkZ2cjNDQUGhoaqFevHhISErBkyRKZxImIiIiUl8Lfdh8TEwNjY2NUrlwZ7du3x08//SS+yyguLg6GhoYyLwDs2LEjVFRUcPr0afTs2RNxcXFo27YtNDQ0xDru7u5YsGABnj9/XugL/bKyspCVlSWuS6XSMuwhyVt5vzqlJK898fX1RURERIHyxMRE2NjYIDg4GNOmTcP8+fPFl2f+9ttv6Nu3L5KTkwu9TdvW1hbdunXDkiVLAAC3b9/G3LlzERUVhSdPnsDc3BwtWrQQX9JJRPQlU+hJ1R4eHti4cSOio6OxYMECxMbGokuXLsjNzQUApKamwtjYWGYfNTU1GBkZITU1Vazz/ksC89fz67wvODgYBgYG4mJhYVHaXSMqtvcvH6ekpIgv2gwNDcWkSZMQGhoq1u/evTuqVKlSaCJ19OhR3L59G35+fgCA+Ph4NG7cGLdu3cL69etx7do17NmzBw4ODggMDCyfDhIRyZFCjxD1799f/NnR0RFOTk6oXbs2YmJi0KFDhzI77pQpU2ReWimVSpkUkdx96PJxbGwsXr9+jdmzZ2Pjxo04efIkWrZsCXV1dQwaNAjh4eH48ccfZfYJDQ1F8+bNUa9ePQiCAF9fX9ja2uLYsWNQUfnf30nOzs4YO3ZsmfeNiEjeFHqE6H21atVC1apVcfv2bQCAqakpHj9+LFPnzZs3ePbsmfjFYWpqikePHsnUyV//0NwkTU1N6OvryyxEiiokJAReXl5QV1eHl5cXQkJCxG1+fn5ITEzE0aNHxbKMjAzs2rVLHB1KSEjA1atXERgYKJMM5TM0NCzzPhARyVuFSoj++ecfPH36FGZmZgAAFxcXpKWl4dy5c2Kdw4cPIy8vD82bNxfrHD16FDk5OWKdqKgo2NvbFzp/iEhRRUZGyrzEs0+fPpBKpdi1axcGDhwIABg4cCB27NghPnqibt26aNGihcyltB07dkAQBHEENjExEQDg4OBQzj0iIlIcck2IMjIykJCQIL44MSkpCQkJCUhOTkZGRgYmTpyIU6dO4d69e4iOjsY333wDGxsbuLu7AwDq1KkDDw8PDB8+HGfOnMGJEycwatQo9O/fH+bm5gCAAQMGQENDA35+frh69Sq2b9+O5cuXy1wSI6oI3NzcxN+XhIQErFixAlu3bkXt2rXRoEEDAG8vcVlaWmL79u3ifkOHDsWuXbvw4sULAG8vl/Xp0wd6enoAPv7CViIiZSHXhCg+Ph4NGzZEw4YNAQDjx49Hw4YNMWPGDKiqquLSpUvo3r077Ozs4Ofnh8aNG+PYsWPQ1NQU29i8eTMcHBzQoUMHfPXVV2jdurXMM4YMDAxw8OBBJCUloXHjxggMDMSMGTN4yz1VODo6OrCxsREXMzMzhISE4OrVq1BTUxOXa9euyYwI5Y8E7dixA4mJiThx4oR4uQwA7OzsAAA3btwo3w4RESkQuU6qdnV1/ehfp3///fcn2zAyMsKWLVs+WsfJyQnHjh0rdnxEiuzy5cuIj49HTEwMjIyMxPJnz57B1dUVN27cgIODA/T09NCnTx+Ehobizp07sLOzQ5s2bcT6zs7OqFu3LhYvXox+/foVmEeUlpbGeURE9MVT6LvMiOjDQkJC0KxZM7Rt27bAtqZNmyIkJASLFi0C8HZydZs2bXD9+nVMnjxZpq5EIkFYWBg6duyINm3aYOrUqXBwcEBGRgb++OMPHDx4ELGxseXSJyIiealQk6qJ6K3s7Gxs2rQJnp6ehW739PTExo0bxZsJWrduDXt7e0ilUgwePLhA/WbNmiE+Ph42NjYYPnw46tSpg+7du+Pq1atYtmxZWXaFiEghSATOqPwkqVQKAwMDpKenl8kt+OX9pOTSUJKnLctbZmYmkpKSYG1tDS0tLXmHQ0QKjp8ZFV9xvr85QkRERERKjwkRERERKT0mRERERKT0mBARERGR0mNCREREREqPCREREREpPSZEREREpPSYEBEREZHSY0JERERESo8JERERESk9vtyVlN4/Pxwr1+PVmN/m05Xe4+vri4iIiALliYmJsLGxQWpqKubOnYv9+/fj33//hbGxMZydnREQEIA2bdrA3NwcEyZMwA8//FCgjTlz5mDVqlX4559/oK6ujuzsbCxbtgybN29GYmIitLW1YW9vj2HDhmHgwIFQV1cvUb+JiBQZEyKiCsLDwwNhYWEyZdWqVcO9e/fQqlUrGBoaYtGiRXB0dEROTg7+/vtv+Pv748aNGxg4cCDCwsIKJESCICA8PByDBw8WkyF3d3dcvHgRc+bMQatWraCvr49Tp07h559/RsOGDeHs7FyOvSYiKh9MiIgqCE1NTZiamhYoHzlyJCQSCc6cOQMdHR2xvF69ehg6dCgAwM/PD8uXL8fx48fRunVrsU5sbCzu3r0LPz8/AMCyZctw9OhRxMfHo2HDhmK9WrVqoU+fPsjOzi6r7hERyRXnEBFVYM+ePcOBAwfg7+8vkwzlMzQ0BAA4OjqiadOmCA0NldkeFhaGli1bwsHBAQCwefNmdOzYUSYZyqeurl7oMYiIvgRMiIgqiMjISOjq6opLnz59cPv2bQiCICY0H+Pn54edO3ciIyMDAPDixQvs2rVLHEUC3s5JKkpbRERfGiZERBWEm5sbEhISxGXFihUQBKHI+3t5eSE3Nxc7duwAAGzfvh0qKiro16+fWKc47RERfUk4h4iogtDR0YGNjY1MmaamJiQSCW7cuPHJ/fX19dG7d2+EhYVh6NChCAsLQ9++faGrqyvWsbOzK1JbRERfGo4QEVVgRkZGcHd3x+rVq/Hy5csC29PS0mTW/fz8cPz4cURGRuLkyZPiZOp8AwYMwKFDh3DhwoUCbeXk5BR6DCKiLwETIqIKbvXq1cjNzUWzZs3w22+/ITExEdevX8eKFSvg4uIiU7dt27awsbHB4MGD4eDggJYtW8psDwgIQKtWrdChQwesXr0aFy9exN27d7Fjxw60aNECiYmJ5dk1IqJyw4SIqIKrVasWzp8/Dzc3NwQGBqJ+/fro1KkToqOjsXbtWpm6EokEQ4cOxfPnz2UmU+fT1NREVFQUJk2ahPXr16NFixZo2rQpVqxYgTFjxqB+/frl1S0ionIlETiL8pOkUikMDAyQnp4OfX39Um9/cb+vS73Nsha4PVLeIRRbZmYmkpKSYG1tDS0tLXmHQ0QKjp8ZFV9xvr85QkRERERKjwkRERERKb0SJUR3794t7TiIiIiI5KZECZGNjQ3c3NywadMmZGZmlnZMREREROWqRAnR+fPn4eTkhPHjx8PU1BTffvstzpw5U9qxEREREZWLEiVEzs7OWL58OR4+fIjQ0FCkpKSgdevWqF+/PpYsWYInT56UdpxEREREZeazJlWrqamhV69e2LlzJxYsWIDbt29jwoQJsLCwwODBg5GSklJacRIRERGVmc9KiOLj4zFy5EiYmZlhyZIlmDBhAu7cuYOoqCg8fPgQ33zzzUf3P3r0KLp16wZzc3NIJBLs3btX3JaTk4PJkyfD0dEROjo6MDc3x+DBg/Hw4UOZNqysrCCRSGSW+fPny9S5dOkS2rRpAy0tLVhYWGDhwoWf020iIiL6wpTo5a5LlixBWFgYbt68ia+++gobN27EV199BRWVt/mVtbU1wsPDYWVl9dF2Xr58iQYNGmDo0KHo1auXzLZXr17h/PnzmD59Oho0aIDnz59j7Nix6N69O+Lj42Xqzp49G8OHDxfX9fT0xJ+lUik6d+6Mjh07Yt26dbh8+TKGDh0KQ0NDjBgxoiTdJyIioi9MiRKitWvXYujQofD19YWZmVmhdYyNjRESEvLRdrp06YIuXboUus3AwABRUVEyZatWrUKzZs2QnJyMmjVriuV6enowNTUttJ3NmzcjOzsboaGh0NDQQL169ZCQkIAlS5YwISIiIiIAJUyIivKCRw0NDfj4+JSk+Q9KT0+HRCKBoaGhTPn8+fMxZ84c1KxZEwMGDMC4ceOgpva2a3FxcWjbti00NDTE+u7u7liwYAGeP3+OypUrFzhOVlYWsrKyxHWpVFqq/SDFEhQUpPDH8/X1RUREBIKDg/HDDz+I5Xv37kXPnj2R/wYeQRCwYcMGhISE4OrVq1BTU4ONjQ0GDhyIESNGQFtbG0FBQZg1axYAQFVVFTVq1EDPnj0xZ84c6OrqlkofiYgqmhLNIQoLC8POnTsLlO/cuRMRERGfHVRhMjMzMXnyZHh5ecm8j2TMmDHYtm0bjhw5gm+//Rbz5s3DpEmTxO2pqakwMTGRaSt/PTU1tdBjBQcHw8DAQFwsLCzKoEdExaOlpSUm8h8yaNAgBAQE4JtvvsGRI0eQkJCA6dOn4/fff8fBgwfFevXq1UNKSgru3buHBQsW4JdffkFgYGB5dIOISCGVKCEKDg5G1apVC5QbGxtj3rx5nx3U+3JyctC3b18IglDg7d3jx4+Hq6srnJyc8N1332Hx4sVYuXKlzAhPcU2ZMgXp6eni8uDBg8/tAtFn69ixI0xNTREcHFzo9h07dmDz5s3YunUrfvzxRzRt2hRWVlb45ptvcPjwYbi5uYl11dTUYGpqiho1aqBfv37w9vbGvn37yqsrREQKp0QJUXJyMqytrQuUW1paIjk5+bODeld+MnT//n1ERUV98m21zZs3x5s3b3Dv3j0AgKmpKR49eiRTJ3/9Q/OONDU1oa+vL7MQyZuqqirmzZuHlStX4p9//imwffPmzbC3ty/07k6JRAIDA4MPtl2pUiVkZ2eXarxERBVJiRIiY2NjXLp0qUD5xYsXUaVKlc8OKl9+MpSYmIhDhw4Vqe2EhASoqKjA2NgYAODi4oKjR48iJydHrBMVFQV7e/tC5w8RKbKePXvC2dkZM2fOLLAtMTER9vb2xW7z3Llz2LJlC9q3b18aIRIRVUglmlTt5eWFMWPGQE9PD23btgUAxMbGYuzYsejfv3+R28nIyMDt27fF9aSkJCQkJMDIyAhmZmbo3bs3zp8/j8jISOTm5opzfoyMjKChoYG4uDicPn0abm5u0NPTQ1xcHMaNG4eBAweKyc6AAQMwa9Ys+Pn5YfLkybhy5QqWL1+OpUuXlqTrRHK3YMECtG/fHhMmTJApz59YXRSXL1+Grq4ucnNzkZ2dja5du2LVqlWlHSoRUYVRooRozpw5uHfvHjp06CDezZWXl4fBgwcXaw5RfHy8zLyG8ePHAwB8fHwQFBQkzmlwdnaW2e/IkSNwdXWFpqYmtm3bhqCgIGRlZcHa2hrjxo0T2wHe3r5/8OBB+Pv7o3HjxqhatSpmzJjBW+6pwmrbti3c3d0xZcoU+Pr6iuV2dna4ceNGkdqwt7fHvn37oKamBnNzc5m7MImIlFGJEiINDQ1s374dc+bMwcWLF1GpUiU4OjrC0tKyWO24urp+9K/aT/3F26hRI5w6deqTx3FycsKxY8eKFRuRIps/fz6cnZ1lLpENGDAA/fv3x++//15gHpEgCJBKpeI8Ig0NDdjY2JRrzEREiqxECVE+Ozs72NnZlVYsRFREjo6O8Pb2xooVK8Syvn37Ys+ePfDy8sK0adPQuXNnVKtWDZcvX8bSpUsxevRo9OjRQ35BExEpsBIlRLm5uQgPD0d0dDQeP36MvLw8me2HDx8uleCI6MNmz56N7du3i+sSiQRbtmzBL7/8gtDQUMydOxdqamqwtbXF4MGD4e7uLsdoiYgUm0QozkzM/2/UqFEIDw9H165dYWZmBolEIrP9S5uwnH+pIT09vUxuwV/c7+tSb7OsBW6PlHcIxZaZmYmkpCRYW1tDS0tL3uEQkYLjZ0bFV5zv7xKNEG3btg07duzAV199VaIAiYiIiBRJiZ5DxAmZRERE9CUpUUIUGBiI5cuXF+u5J0RERESKqkSXzI4fP44jR47gr7/+Qr169aCuri6zfffu3aUSHBEREVF5KFFCZGhoiJ49e5Z2LERERERyUaKEKCwsrLTjICIiIpKbEs0hAoA3b97g0KFDWL9+PV68eAEAePjwITIyMkotOCIiIqLyUKIRovv378PDwwPJycnIyspCp06doKenhwULFiArKwvr1q0r7TiJiIiIykyJRojGjh2LJk2a4Pnz56hUqZJY3rNnT0RHR5dacERERETloUQjRMeOHcPJkycLvCHbysoK//77b6kERkRERFReSpQQ5eXlITc3t0D5P//8Az09vc8Oiqg8RR+uXa7H69D+Ton2S01Nxdy5c7F//378+++/MDY2hrOzMwICAtChQwexXnBwMKZNm4b58+dj4sSJMm2Eh4djyJAhBdrW1NREZmZmsY9FRPSlKNEls86dO2PZsmXiukQiQUZGBmbOnMnXeRCVgXv37qFx48Y4fPgwFi1ahMuXL+PAgQNwc3ODv7+/TN3Q0FBMmjQJoaGhhbalr6+PlJQUmeX+/fslOhYR0ZeiRCNEixcvhru7O+rWrYvMzEwMGDAAiYmJqFq1KrZu3VraMRIpvZEjR0IikeDMmTPQ0dERy+vVq4ehQ4eK67GxsXj9+jVmz56NjRs34uTJk2jZsqVMWxKJBKampp99LCKiL0mJEqIaNWrg4sWL2LZtGy5duoSMjAz4+fnB29tbZpI1EX2+Z8+e4cCBA5g7d65MgpLP0NBQ/DkkJAReXl5QV1eHl5cXQkJCCiREpXUsIqIvSYkSIgBQU1PDwIEDSzMWIirE7du3IQgCHBwcPlpPKpVi165diIuLAwAMHDgQbdq0wfLly6GrqyvWS09Pl1kHgDZt2uCvv/4q8rGIiL40JUqINm7c+NHtgwcPLlEwRFRQUV+ivHXrVtSuXRsNGjQAADg7O8PS0hLbt2+Hn5+fWE9PTw/nz5+X2Td/ZJcvbCYiZVWihGjs2LEy6zk5OXj16hU0NDSgra3NhIioFNna2kIikeDGjRsfrRcSEoKrV69CTe1/v9Z5eXkIDQ2VSYhUVFRgY2PzWcciIvrSlOgus+fPn8ssGRkZuHnzJlq3bs1J1USlzMjICO7u7li9ejVevnxZYHtaWhouX76M+Ph4xMTEICEhQVxiYmIQFxdX5ASnKMciIvoSlfhdZu+ztbXF/PnzC4weEdHnW716NXJzc9GsWTP89ttvSExMxPXr17FixQq4uLggJCQEzZo1Q9u2bVG/fn1xadu2LZo2bYqQkBCxLUEQkJqaWmDJy8sr0rGIiL5EpZYQAW8nWj98+LA0myQiALVq1cL58+fh5uaGwMBA1K9fH506dUJ0dDSWL1+OTZs2wdPTs9B9PT09sXHjRuTk5AB4O/nazMyswPL48eNPHmvt2rXl1mciovIkEUowi3Lfvn0y64IgICUlBatWrYKFhQX++uuvUgtQEUilUhgYGCA9PR36+vql3v7ifl+XeptlLXB7pLxDKLbMzEwkJSXB2toaWlpa8g6HiBQcPzMqvuJ8f5doUnWPHj1k1iUSCapVq4b27dtj8eLFJWmSiIiISG5K/C4zIiIioi9Fqc4hIiIiIqqISjRCNH78+CLXXbJkSUkOQURERFRuSpQQXbhwARcuXEBOTg7s7e0BALdu3YKqqioaNWok1pNIJKUTJREREVEZKlFC1K1bN+jp6SEiIgKVK1cG8PZhjUOGDEGbNm0QGBhYqkESERERlaUSzSFavHgxgoODxWQIACpXroyffvqpWHeZHT16FN26dYO5uTkkEgn27t0rs10QBMyYMQNmZmaoVKkSOnbsiMTERJk6z549g7e3N/T19WFoaAg/Pz9kZGTI1Ll06RLatGkDLS0tWFhYYOHChcXvNBEREX2xSpQQSaVSPHnypED5kydP8OLFiyK38/LlSzRo0ACrV68udPvChQuxYsUKrFu3DqdPn4aOjg7c3d2RmZkp1vH29sbVq1cRFRWFyMhIHD16FCNGjJCJtXPnzrC0tMS5c+ewaNEiBAUF4ZdffilGj4mIiOhLVqJLZj179sSQIUOwePFiNGvWDABw+vRpTJw4Eb169SpyO126dEGXLl0K3SYIApYtW4Zp06bhm2++AQBs3LgRJiYm2Lt3L/r374/r16/jwIEDOHv2LJo0aQIAWLlyJb766iv8/PPPMDc3x+bNm5GdnY3Q0FBoaGigXr16SEhIwJIlS2QSJyIiIlJeJRohWrduHbp06YIBAwbA0tISlpaWGDBgADw8PLBmzZpSCSwpKQmpqano2LGjWGZgYIDmzZsjLi4OABAXFwdDQ0MxGQKAjh07QkVFBadPnxbrtG3bFhoaGmIdd3d33Lx5E8+fPy+VWImIiKhiK9EIkba2NtasWYNFixbhzp07AIDatWtDR0en1AJLTU0FAJiYmMiUm5iYiNtSU1NhbGwss11NTQ1GRkYydaytrQu0kb/t3XlQ+bKyspCVlSWuS6XSz+wNKTLTIwnlerxUN+di7/PkyRPMmDED+/fvx6NHj1C5cmU0aNAAM2bMQKtWrWBlZYX79+9j69at6N+/v8y+9erVw7Vr1xAWFgZfX1+x/OTJk/jpp58QFxeH169fw9bWFkOGDMHYsWOhqqoq1pNIJNizZ4/4hPqcnBwMHjwYR48exd9//4369et/8I7SwuIhIlJEn/VgxpSUFKSkpMDW1hY6OjoowWvRFFJwcDAMDAzExcLCQt4hkZLz9PTEhQsXEBERgVu3bmHfvn1wdXXF06dPxToWFhYICwuT2e/UqVNITU0t8MfKnj170K5dO9SoUQNHjhzBjRs3MHbsWPz000/o37//B3+XX716he7du+Ps2bM4fvw46tevL24LCwsTPxPyl/df80NEpKhKNEL09OlT9O3bF0eOHIFEIkFiYiJq1aoFPz8/VK5cuVTeZ2ZqagoAePToEczMzMTyR48ewdnZWayT/4bufG/evMGzZ8/E/U1NTfHo0SOZOvnr+XXeN2XKFJmHT0qlUiZFJDdpaWk4duwYYmJi0K5dOwCApaWlOH8vn7e3N5YuXYoHDx6I/19DQ0Ph7e2NjRs3ivVevnyJ4cOHo3v37jI3FwwbNgwmJibo3r07duzYgX79+hWIo2vXrsjIyMDx48cL/P4YGhp+8HeKiEjRlWiEaNy4cVBXV0dycjK0tbXF8n79+uHAgQOlEpi1tTVMTU0RHR0tlkmlUpw+fRouLi4AABcXF6SlpeHcuXNincOHDyMvLw/NmzcX6xw9ehQ5OTlinaioKNjb2xd6uQwANDU1oa+vL7MQyYuuri50dXWxd+9emUu57zMxMYG7uzsiIiIAvB3N2b59O4YOHSpT7+DBg3j69CkmTJhQoI1u3brBzs4OW7dulSlPTU0Vk7HY2FgmPkT0xSlRQnTw4EEsWLAANWrUkCm3tbXF/fv3i9xORkYGEhISkJCQAODtROqEhAQkJydDIpEgICAAP/30E/bt24fLly9j8ODBMDc3F4fh69SpAw8PDwwfPhxnzpzBiRMnMGrUKPTv3x/m5uYAgAEDBkBDQwN+fn64evUqtm/fjuXLlxfr9SNE8qSmpobw8HBERETA0NAQrVq1wo8//ohLly4VqDt06FCEh4dDEATs2rULtWvXFkdU8926dQvA29+fwjg4OIh18o0dOxbZ2dmIioqCoaFhoft5eXmJyVv+kpycXPwOExHJQYkSopcvX8qMDOV79uwZNDU1i9xOfHw8GjZsiIYNGwJ4+460hg0bYsaMGQCASZMmYfTo0RgxYgSaNm2KjIwMHDhwAFpaWmIbmzdvhoODAzp06ICvvvoKrVu3lrkMYGBggIMHDyIpKQmNGzdGYGAgZsyYwVvuqULx9PTEw4cPsW/fPnh4eCAmJgaNGjVCeHi4TL38S1pHjx5FaGhogdGhdxVnzt/XX3+NW7duYf369R+ss3TpUvEPnPwl/w8TIiJFV6I5RG3atMHGjRsxZ84cAG/vQsnLy8PChQvh5uZW5HZcXV0/+qEskUgwe/ZszJ49+4N1jIyMsGXLlo8ex8nJCceOHStyXESKSEtLC506dUKnTp0wffp0DBs2DDNnzpS5c0xNTQ2DBg3CzJkzcfr0aezZs6dAO3Z2dgCA69evo2XLlgW2X79+HXXr1pUpGzRoELp3746hQ4dCEIRCR1hNTU1hY2Pzmb0kIpKPEiVECxcuRIcOHRAfH4/s7GxMmjQJV69exbNnz3DixInSjpGIClG3bt0Cr7sB3l42+/nnn9GvX79C58l17twZRkZGWLx4cYGEaN++fUhMTBT/2HmXj48PVFRUMGTIEOTl5RU6B4mIqKIqUUJUv3593Lp1C6tWrYKenh4yMjLQq1cv+Pv7y9wRRkSf7+nTp+jTpw+GDh0KJycn6OnpIT4+HgsXLhSf4v6uOnXq4L///iv0sjYA6OjoYP369ejfvz9GjBiBUaNGQV9fH9HR0Zg4cSJ69+6Nvn37FrrvoEGDoKKiAh8fHwiCgIkTJ4rb0tLSxOd/5dPT0yvV55MREZWVYidEOTk58PDwwLp16zB16tSyiImI3qGrq4vmzZtj6dKluHPnDnJycmBhYYHhw4fjxx9/LHSfKlWqfLTN3r1748iRI5g7dy7atGmDzMxM2NraYurUqQgICPjggxaBt7f3q6ioYNCgQcjLy8PkyZMBAEOGDClQNzg4GD/88EMxektEJB8SoQRPU6xWrRpOnjwJW1vbsohJ4UilUhgYGCA9Pb1MbsFf3O/rUm+zrAVuj5R3CMWWmZmJpKQkWFtby0zMJyIqDD8zKr7ifH+X6C6zgQMHIiQkpETBERERESmaEs0hevPmDUJDQ3Ho0CE0bty4wByBJUuWlEpwREREROWhWAnR3bt3YWVlhStXrqBRo0YAUOABbh+be0BERESkiIqVENna2iIlJQVHjhwB8PZVHStWrCjwRnoiIiKiiqRYc4jen3/9119/4eXLl6UaEBEREVF5K9Gk6nwluEGNiIiISOEUKyGSSCQF5ghxzhARERFVdMWaQyQIAnx9fcUXuGZmZuK7774rcJfZ7t27Sy9CIiIiojJWrITIx8dHZn3gwIGlGgwRERGRPBQrIQoLCyurOIiIiIjkpkQPZiT6klj9sL9cj3dvftcS7Zeamoq5c+di//79+Pfff2FsbAxnZ2cEBASgQ4cOsLKyQkBAAAICAmT2CwoKwt69e5GQkAAA2LBhAzZu3IgrV64AABo3box58+ahWbNmMvtdvXoVs2bNwpEjRyCVSmFpaYn+/fvjhx9++OCLY4mIKqrPusuMiMrHvXv30LhxYxw+fBiLFi3C5cuXceDAAbi5ucHf379YbcXExMDLywtHjhxBXFwcLCws0LlzZ/z7779inVOnTqF58+bIzs7G/v37cevWLcydOxfh4eHo1KkTsrOzS7uLRERyxREiogpg5MiRkEgkOHPmjMxNDPXq1cPQoUOL1dbmzZtl1n/99Vf89ttviI6OxuDBgyEIAvz8/FCnTh3s3r0bKipv/26ytLSEnZ0dGjZsiKVLl4pvuSci+hJwhIhIwT179gwHDhyAv79/gTs6AcDQ0PCz2n/16hVycnJgZGQEAEhISMC1a9cwfvx4MRnK16BBA3Ts2BFbt279rGMSESkaJkRECu727dsQBAEODg6frDt58mTo6urKLPPmzfvkPubm5ujYsSOA/72fsE6dOoXWr1OnToF3GBIRVXS8ZEak4IrzRPiJEyfC19dXpmzFihU4evRoofXnz5+Pbdu2ISYmBlpaWiU+LhFRRceEiEjB2draQiKR4MaNG5+sW7VqVdjY2MiU5V8Ke9/PP/+M+fPn49ChQ3BychLL7ezsAADXr19Hw4YNC+x3/fp1sQ4R0ZeCl8yIFJyRkRHc3d2xevXqQl+mnJaWVuw2Fy5ciDlz5uDAgQNo0qSJzDZnZ2c4ODhg6dKlyMvLk9l28eJFHDp0CF5eXsU+JhGRImNCRFQBrF69Grm5uWjWrBl+++03JCYm4vr161ixYgVcXFyK1daCBQswffp0hIaGwsrKCqmpqUhNTUVGRgaAt+8nDAkJwbVr1+Dp6YkzZ84gOTkZO3fuRLdu3eDi4lLgWUdERBUdEyKiCqBWrVo4f/483NzcEBgYiPr166NTp06Ijo7G2rVri9XW2rVrkZ2djd69e8PMzExcfv75Z7FOy5YtcerUKaiqqqJLly6wsbHBlClT4OPjg6ioKPF9hkREXwqJwJmTnySVSmFgYID09HTo6+uXevuL+31d6m2WtcDtkfIOodgyMzORlJQEa2vrAhOIiYjex8+Miq84398cISIiIiKlx4SIiIiIlB4TIiIiIlJ6TIiIiIhI6TEhIiIiIqXHhIiIiIiUnsInRFZWVpBIJAUWf39/AICrq2uBbd99951MG8nJyejatSu0tbVhbGyMiRMn4s2bN/LoDhERESkghX+X2dmzZ5GbmyuuX7lyBZ06dUKfPn3EsuHDh2P27Nniura2tvhzbm4uunbtClNTU5w8eRIpKSkYPHgw1NXVP/kWcCIiIlIOCp8QVatWTWZ9/vz5qF27Ntq1ayeWaWtrw9TUtND9Dx48iGvXruHQoUMwMTGBs7Mz5syZg8mTJyMoKAgaGhplGj8REREpPoW/ZPau7OxsbNq0CUOHDoVEIhHLN2/ejKpVq6J+/fqYMmUKXr16JW6Li4uDo6MjTExMxDJ3d3dIpVJcvXq10ONkZWVBKpXKLERERPTlUvgRonft3bsXaWlp8PX1FcsGDBgAS0tLmJub49KlS5g8eTJu3ryJ3bt3AwBSU1NlkiEA4npqamqhxwkODsasWbPKphOkeIIMyvl46cXe5cmTJ5gxYwb279+PR48eoXLlymjQoAFmzJiBVq1aAQAuXLiAefPm4ejRo0hPT4eFhQVcXV0xceJE2NnZiW399ttvWLlyJS5cuIDc3FzUqlULvXv3xqhRo2BkZFRq3SQiqkgq1AhRSEgIunTpAnNzc7FsxIgRcHd3h6OjI7y9vbFx40bs2bMHd+7cKfFxpkyZgvT0dHF58OBBaYRPVGKenp64cOECIiIicOvWLezbtw+urq54+vQpACAyMhItWrRAVlYWNm/ejOvXr2PTpk0wMDDA9OnTxXamTp2Kfv36oWnTpvjrr79w5coVLF68GBcvXsT//d//yat7RERyV2FGiO7fv49Dhw6JIz8f0rx5cwDA7du3Ubt2bZiamuLMmTMydR49egQAH5x3pKmpybd5k8JIS0vDsWPHEBMTI86ds7S0RLNmzQAAr169wpAhQ/DVV19hz5494n7W1tZo3rw50tLSAABnzpzBvHnzsGzZMowdO1asZ2VlhU6dOon1iIiUUYUZIQoLC4OxsTG6du360XoJCQkAADMzMwCAi4sLLl++jMePH4t1oqKioK+vj7p165ZZvESlRVdXF7q6uti7dy+ysrIKbP/777/x33//YdKkSYXub2hoCODtXDtdXV2MHDnyo/WIiJRRhUiI8vLyEBYWBh8fH6ip/W9Q686dO5gzZw7OnTuHe/fuYd++fRg8eDDatm0LJycnAEDnzp1Rt25dDBo0CBcvXsTff/+NadOmwd/fn6NAVCGoqakhPDwcERERMDQ0RKtWrfDjjz/i0qVLAIDExEQAgIODw0fbSUxMRK1ataCurl7mMRMRVTQVIiE6dOgQkpOTMXToUJlyDQ0NHDp0CJ07d4aDgwMCAwPh6emJP/74Q6yjqqqKyMhIqKqqwsXFBQMHDsTgwYNlnltEpOg8PT3x8OFD7Nu3Dx4eHoiJiUGjRo0QHh4OQRCK1EZR6xERKaMKMYeoc+fOhX6YW1hYIDY29pP7W1pa4s8//yyL0IjKjZaWFjp16oROnTph+vTpGDZsGGbOnIlly5YBAG7cuAEXF5cP7m9nZ4fjx48jJyeHo0RERO+pEAkRKZ5/fjgm7xCKrWpQU3mHUKrq1q2LvXv3onPnzqhatSoWLlwoM6k6X1paGgwNDTFgwACsWLECa9askZlU/X49IiJlxISISME9ffoUffr0wdChQ+Hk5AQ9PT3Ex8dj4cKF+Oabb6Cjo4Nff/0Vffr0Qffu3TFmzBjY2Njgv//+w44dO5CcnIxt27ahefPmmDRpEgIDA/Hvv/+iZ8+eMDc3x+3bt7Fu3Tq0bt260ESJiEgZMCEiUnC6urpo3rw5li5dijt37iAnJwcWFhYYPnw4fvzxRwDAN998g5MnTyI4OBgDBgyAVCqFhYUF2rdvj59++klsa8GCBWjcuDFWr16NdevWIS8vD7Vr10bv3r3h4+Mjry4SEcmdROBMy0+SSqUwMDBAeno69PX1S739xf2+LvU2y1o/68nyDqHYqgY1RVJSEqytraGlpSXvcIhIwWVmZvIzo4Irzvd3hbjLjIiIiKgsMSEiIiIipcc5REREVG6y/3kh7xCKLPtNNt48zwSs5R0JlQeOEBEREZHSY0JERERESo8JERERESk9JkRERESk9JgQERERkdJjQkRERERKjwkRERERKT0+h4iUnmOEY7ke77LP5WLv4+vri4iIiALliYmJsLGxQXBwMKZNm4b58+dj4sSJMnXCw8MxZMiQAvtu2LABw4YNK3YsRERfIiZERBWEh4cHwsLCZMqqVasGAAgNDcWkSZMQGhpaICECAH19fdy8eVOmzMDAoOyCJSKqYJgQEVUQmpqaMDU1LVAeGxuL169fY/bs2di4cSNOnjyJli1bytSRSCSF7ktERG9xDhFRBRcSEgIvLy+oq6vDy8sLISEh8g6JiKjCYUJEVEFERkZCV1dXXPr06QOpVIpdu3Zh4MCBAICBAwdix44dyMjIkNk3PT1dZl+OFhERyeIlM6IKws3NDWvXrhXXdXR0sHXrVtSuXRsNGjQAADg7O8PS0hLbt2+Hn5+fWFdPTw/nz58X11VU+LcQEdG7mBARVRA6OjqwsbGRKQsJCcHVq1ehpva/X+W8vDyEhobKJEQqKioF9iUiov9hQkRUQV2+fBnx8fGIiYmBkZGRWP7s2TO4urrixo0bcHBwkGOEREQVBxMiogoqJCQEzZo1Q9u2bQtsa9q0KUJCQrBo0SI5REZEVPFwIgFRBZSdnY1NmzbB09Oz0O2enp7YuHEjcnJyyjkyIqKKSSIIgiDvIBSdVCqFgYEB0tPToa+vX+rtL+73dam3Wdb6WU+WdwjFVjWoKZKSkmBtbQ0tLS15h0OklLL/eSHvEIos80027j9Mhm2jOvzMqKCK8/3NESIiIiJSekyIiIiISOkxISIiIiKlx4SIiIiIlB4TIiIiIlJ6TIiIiIhI6Sl0QhQUFASJRCKzvPvk3czMTPj7+6NKlSrQ1dWFp6cnHj16JNNGcnIyunbtCm1tbRgbG2PixIl48+ZNeXeFiIiIFJjCP6m6Xr16OHTokLj+7jubxo0bh/3792Pnzp0wMDDAqFGj0KtXL5w4cQIAkJubi65du8LU1BQnT55ESkoKBg8eDHV1dcybN6/c+0JERESKSeETIjU1NZiamhYoT09PR0hICLZs2YL27dsDAMLCwlCnTh2cOnUKLVq0wMGDB3Ht2jUcOnQIJiYmcHZ2xpw5czB58mQEBQVBQ0OjvLtDRERECkihL5kBQGJiIszNzVGrVi14e3sjOTkZAHDu3Dnk5OSgY8eOYl0HBwfUrFkTcXFxAIC4uDg4OjrCxMRErOPu7g6pVIqrV69+8JhZWVmQSqUyCxEREX25FHqEqHnz5ggPD4e9vT1SUlIwa9YstGnTBleuXEFqaio0NDRgaGgos4+JiQlSU1MBAKmpqTLJUP72/G0fEhwcjFmzZpVuZ0hhXXeoU67Hq3PjepHrSiSSj26fOXMmXF1d4ebmhufPnxf4fbCyskJAQAACAgI+2t7WrVvRv3//IsdFRPSlUeiEqEuXLuLPTk5OaN68OSwtLbFjxw5UqlSpzI47ZcoUjB8/XlyXSqWwsLAos+MRfUhKSor48/bt2zFjxgzcvHlTLNPV1UV8fHyx2gwLC4OHh4dM2fuJFBGRslHohOh9hoaGsLOzw+3bt9GpUydkZ2cjLS1N5sP80aNH4pwjU1NTnDlzRqaN/LvQCpuXlE9TUxOampql3wGiYnr3/6mBgQEkEslH/+8WhaGh4We3QUT0pVH4OUTvysjIwJ07d2BmZobGjRtDXV0d0dHR4vabN28iOTkZLi4uAAAXFxdcvnwZjx8/FutERUVBX18fdevWLff4iYiISDEp9AjRhAkT0K1bN1haWuLhw4eYOXMmVFVV4eXlBQMDA/j5+WH8+PEwMjKCvr4+Ro8eDRcXF7Ro0QIA0LlzZ9StWxeDBg3CwoULkZqaimnTpsHf358jQKS0vLy8oKqqKlN27do11KxZU04RERHJn0InRP/88w+8vLzw9OlTVKtWDa1bt8apU6dQrVo1AMDSpUuhoqICT09PZGVlwd3dHWvWrBH3V1VVRWRkJL7//nu4uLhAR0cHPj4+mD17try6RCR3S5culbk7EwDMzc3lFA0RkWJQ6IRo27ZtH92upaWF1atXY/Xq1R+sY2lpiT///LO0QyNSGPr6+gDePpvr/cnRaWlpMDAwkCkzNTWFjY1NeYVHRFQhVKg5RERUkK2tLVRUVHDu3DmZ8rt37yI9PR12dnZyioyIqOJQ6BEiIvo0PT09DBs2DIGBgVBTU4OjoyMePHiAyZMno0WLFmjZsqVM/bS0tALP4dLT04OOjk55hk1EpFA4QkT0BVi+fDl8fHwwefJk1KtXD76+vnBycsIff/xR4GGMQ4YMgZmZmcyycuVKOUVORKQYOEJESq84T46WJ19fX/j6+ha6TUtLC0FBQQgKCvpoG4IglH5gRERfAI4QERERkdJjQkRERERKjwkRERERKT0mRERERKT0OKmaiIjKTW7afXmHUGR5eXkQXj+TdxhUTjhCREREREqPCREREREpPSZEREREpPSYEBEREZHSY0JERERESo93mZHSW/3d4XI9nv+69sXex9fXFxEREfj222+xbt062fb8/bFmzRr4+PggIiLio+3MnDkTvr6+sLa2FssqV64MR0dH/PTTT2jTpk2Bfb799lv8+uuv2LZtG/r06SOzLSgoCLNmzSoQV0JCAho2bIikpCRYWVkBAPbs2YMFCxbg+vXryMvLQ82aNdGpUycsW7asmGeDiKj0cYSIqIKwsLDAtm3b8Pr1a7EsMzMTW7ZsQc2aNQEAKSkp4rJs2TLo6+vLlE2YMEHc99ChQ0hJScHRo0dhbm6Or7/+Go8ePZI55qtXr7Bt2zZMmjQJoaGhhcalpaWFkJAQJCYmfjD26Oho9OvXD56enjhz5gzOnTuHuXPnIicn53NOCRFRqWFCRFRBNGrUCBYWFti9e7dYtnv3btSsWRMNGzYEAJiamoqLgYEBJBKJTJmurq64b5UqVWBqaor69evjxx9/hFQqxenTp2WOuXPnTtStWxc//PADjh49igcPHhSIy97eHm5ubpg6deoHY//jjz/QqlUrTJw4Efb29rCzs0OPHj2wevXqzz0tRESlggkRUQUydOhQhIWFieuhoaEYMmTIZ7X5+vVrbNy4EQCgoaEhsy0kJAQDBw6EgYEBunTpgvDw8ELbmD9/Pn777TfEx8cXut3U1BRXr17FlStXPitWIqKywoSIqAIZOHAgjh8/jvv37+P+/fs4ceIEBg4cWKK2WrZsCV1dXejo6ODnn39G48aN0aFDB3F7YmIiTp06hX79+onHDgsLgyAIBdpq1KgR+vbti8mTJxd6rNGjR6Np06ZwdHSElZUV+vfvj9DQUGRlZZUodiKi0saEiKgCqVatGrp27Yrw8HCEhYWha9euqFq1aona2r59Oy5cuIDffvsNNjY2CA8Ph7q6urg9NDQU7u7uYvtfffUV0tPTcfhw4ZPQf/rpJxw7dgwHDx4ssE1HRwf79+/H7du3MW3aNOjq6iIwMBDNmjXDq1evShQ/EVFp4l1mRBXM0KFDMWrUKAD4rDk4FhYWsLW1ha2tLd68eYOePXviypUr0NTURG5uLiIiIpCamgo1tf99TOTm5iI0NFRmJClf7dq1MXz4cPzwww8ICQkp9Ji1a9dG7dq1MWzYMEydOhV2dnbYvn37Z1/2IyL6XBwhIqpgPDw8kJ2djZycHLi7u5dKm71794aamhrWrFkDAPjzzz/x4sULXLhwAQkJCeKydetW7N69G2lpaYW2M2PGDNy6dQvbtm375DGtrKygra2Nly9flkofiIg+B0eIiCoYVVVVXL9+Xfy5NEgkEowZMwZBQUH49ttvERISgq5du6JBgwYy9erWrYtx48Zh8+bN8Pf3L9COiYkJxo8fj0WLFsmUBwUF4dWrV/jqq69gaWmJtLQ0rFixAjk5OejUqVOp9IGI6HNwhIioAtLX14e+vn6ptunj44OcnBysXLkS+/fvh6enZ4E6Kioq6Nmz5wcviQHAhAkTZG7vB4B27drh7t27GDx4MBwcHNClSxekpqbi4MGDsLe3L9V+EBGVhEQo7JYRkiGVSmFgYID09PRS/xICgMX9vi71NstaP+vC7yZSZFWDmiIpKQnW1tbQ0tKSdzhESul1BXr0QlZeHpKfPIFdq1b8zKigivP9zREiIiIiUnpMiIiIiEjpMSEiIiIipceEiIiIiJQeEyIiIiJSegqdEAUHB6Np06bQ09ODsbExevTogZs3b8rUcXV1hUQikVm+++47mTrJycno2rUrtLW1YWxsjIkTJ+LNmzfl2RUiIiJSYAr9YMbY2Fj4+/ujadOmePPmDX788Ud07twZ165dg46Ojlhv+PDhmD17triura0t/pybm4uuXbvC1NQUJ0+eREpKCgYPHgx1dXXMmzevXPtDREREikmhE6IDBw7IrIeHh8PY2Bjnzp1D27ZtxXJtbW2YmpoW2sbBgwdx7do1HDp0CCYmJnB2dsacOXMwefJkBAUFQUNDo0z7QERERIpPoS+ZvS89PR0AYGRkJFO+efNmVK1aFfXr18eUKVNk3p4dFxcHR0dHmJiYiGXu7u6QSqW4evVq+QRORERECq3CJER5eXkICAhAq1atUL9+fbF8wIAB2LRpE44cOYIpU6bg//7v/zBw4EBxe2pqqkwyBEBcT01NLfRYWVlZkEqlMgvRlyQoKAjOzs7yDqPYYmJiIJFIPvhy2aJydXVFQEBAqcRERF8Ghb5k9i5/f39cuXIFx48flykfMWKE+LOjoyPMzMzQoUMH3LlzB7Vr1y7RsYKDgzFr1qzPipcqjvJ+dUrg9shi7+Pr64uIiAgEBwfjhx9+EMv37t2Lnj17Iv8NPLm5uVixYgVCQ0ORmJiISpUqoUWLFpg2bRpatWpVan0gIvrSVIgRolGjRiEyMhJHjhxBjRo1Plq3efPmAIDbt28DAExNTfHo0SOZOvnrH5p3NGXKFKSnp4vLgwcPPrcLRJ9NS0sLCxYswPPnzwvdLggC+vfvj9mzZ2Ps2LG4fv06YmJiYGFhAVdXV+zdu7d8AyYiqkAUOiESBAGjRo3Cnj17cPjwYVhbW39yn4SEBACAmZkZAMDFxQWXL1/G48ePxTpRUVHQ19dH3bp1C21DU1NTfJt4WbxVnKgkOnbsCFNTUwQHBxe6fceOHdi1axc2btyIYcOGwdraGg0aNMAvv/yC7t27Y9iwYXj58qXMPuvXr4eFhQW0tbXRt29fcZ5evl9//RV16tSBlpYWHBwcsGbNGnFb+/btMWrUKJn6T548gYaGBqKjowG8vfw8YcIEVK9eHTo6OmjevDliYmLE+vfv30e3bt1QuXJl6OjooF69evjzzz/F7X/++Sfs7OxQqVIluLm54d69ezLHe/r0Kby8vFC9enVoa2vD0dERW7dulanz8uVLDB48GLq6ujAzM8PixYs/fqKJSCkpdELk7++PTZs2YcuWLdDT00NqaipSU1Px+vVrAMCdO3cwZ84cnDt3Dvfu3cO+ffswePBgtG3bFk5OTgCAzp07o27duhg0aBAuXryIv//+G9OmTYO/vz80NTXl2T2iYlFVVcW8efOwcuVK/PPPPwW2b9myBXZ2dujWrVuBbYGBgXj69CmioqLEstu3b2PHjh34448/cODAAVy4cAEjR44Ut2/evBkzZszA3Llzcf36dcybNw/Tp09HREQEAGDYsGHYsmULsrKyxH02bdqE6tWro3379gDeju7GxcVh27ZtuHTpEvr06QMPDw8kJiYCePs7npWVhaNHj+Ly5ctYsGABdHV1AQAPHjxAr1690K1bNyQkJGDYsGEylwsBIDMzE40bN8b+/ftx5coVjBgxAoMGDcKZM2fEOhMnTkRsbCx+//13HDx4EDExMTh//nyxzz8RfdkUeg7R2rVrAbydAPmusLAw+Pr6QkNDA4cOHcKyZcvw8uVLWFhYwNPTE9OmTRPrqqqqIjIyEt9//z1cXFygo6MDHx8fmecWEVUUPXv2hLOzM2bOnImQkBCZbbdu3UKdOnUK3S+//NatW2JZZmYmNm7ciOrVqwMAVq5cia5du2Lx4sUwNTXFzJkzsXjxYvTq1QsAYG1tjWvXrmH9+vXw8fFBr169MGrUKPz+++/o27cvgLePxvD19YVEIkFycjLCwsKQnJwMc3NzAMCECRNw4MABhIWFYd68eUhOToanpyccHR0BALVq1RLjW7t2LWrXri2O6Njb24tJU77q1atjwoQJ4vro0aPx999/Y8eOHWjWrBkyMjIQEhKCTZs2oUOHDgCAiIiIT156J6rorjsU/lmgyOrcuC7X4yt0QpQ/UfRDLCwsEBsb+8l2LC0tZYbhiSqyBQsWoH379jKJQL5P/c68q2bNmmIyBLy9vJyXl4ebN29CT08Pd+7cgZ+fH4YPHy7WefPmDQwMDAC8ndM0aNAghIaGom/fvjh//jyuXLmCffv2AQAuX76M3Nxc2NnZyRw3KysLVapUAQCMGTMG33//PQ4ePIiOHTvC09NTHN29fv26OCfw3RjflZubi3nz5mHHjh34999/kZ2djaysLPHhrHfu3EF2drZMO0ZGRrC3ty/yeSIi5aDQCRERFdS2bVu4u7tjypQp8PX1Fcvt7Oxw/Xrhf2Hll7+fnHxIRkYGAGDDhg0FkhJVVVXx52HDhsHZ2Rn//PMPwsLC0L59e1haWoptqKqq4ty5czL7ABAviw0bNgzu7u7Yv38/Dh48iODgYCxevBijR48uUpyLFi3C8uXLsWzZMjg6OkJHRwcBAQHIzs4u0v5ERPkUeg4RERVu/vz5+OOPPxAXFyeW9e/fH4mJifjjjz8K1F+8eDGqVKmCTp06iWXJycl4+PChuH7q1CmoqKjA3t4eJiYmMDc3x927d2FjYyOzvHtzg6OjI5o0aYINGzZgy5YtGDp0qLitYcOGyM3NxePHjwu08e4dnhYWFvjuu++we/duBAYGYsOGDQDeXuZ7dy5QfozvOnHiBL755hsMHDgQDRo0QK1atWQuC9auXRvq6uo4ffq0WPb8+XOZOkREAEeIiCokR0dHeHt7Y8WKFWJZ//79sXPnTvj4+GDRokXo0KEDpFIpVq9ejX379mHnzp0y7wDU0tKCj48Pfv75Z0ilUowZMwZ9+/YVk5VZs2ZhzJgxMDAwgIeHB7KyshAfH4/nz59j/PjxYjvDhg3DqFGjoKOjg549e4rldnZ28Pb2xuDBg7F48WI0bNgQT548QXR0NJycnNC1a1cEBASgS5cusLOzw/Pnz3HkyBFxvtN3332HxYsXY+LEiRg2bBjOnTuH8PBwmfNga2uLXbt24eTJk6hcuTKWLFmCR48eiXeQ6urqws/PDxMnTkSVKlVgbGyMqVOnQkWFfwsSkSwmRKT0SvKgREUwe/ZsbN++XVyXSCTYsWMHli1bhqVLl2LkyJHQ0tKCi4sLYmJiCjyY0cbGBr169cJXX32FZ8+e4euvv5a5rX7YsGHQ1tbGokWLMHHiROjo6MDR0bHAE569vLwQEBAALy8vaGlpyWwLCwvDTz/9hMDAQPz777+oWrUqWrRoga+/fvswzNzcXPj7++Off/6Bvr4+PDw8sHTpUgBv5zj99ttvGDduHFauXIlmzZph3rx5MqNQ06ZNw927d+Hu7g5tbW2MGDECPXr0kHl8wKJFi5CRkYFu3bpBT08PgYGBBR4vQEQkEYozC1NJSaVSGBgYID09vUyeSVTeT0ouDf2sJ8s7hGKrGtQUSUlJsLa2LvDFTSV379491K5dG2fPnkWjRo3kHQ4puNdXrsg7hCLLystD8pMnsGvVqsJ9ZvAus7eK8/3NESIiKpGcnBw8ffoU06ZNQ4sWLZgMEVGFxgvpRFQiJ06cgJmZGc6ePYt169bJOxwios/CESIiKhFXV9diPfeIiEiRcYSIiIiIlB4TIlI6HNUgoqIQAICfF0qDCREpDXV1dQDAq1ev5BwJEVUEmYIAISdH/OygLxvnEJHSUFVVhaGhIR4/fgwA0NbWhkQikXNURMolKy9P3iF8koC3ydB/z9MgiYmFapcu8g6JygETIlIq+U9hzk+KiKh85Tx5Iu8QPu3/jwxJYmKhtm8fsGC+vCOicsCEiJSKRCKBmZkZjI2NkZOTI+9wiJTOnZH+8g7h0wQBkrQ0SDIz5R0JlSMmRKSUVFVVC7yBnYjKnkpKirxDICoUJ1UTERGR0uMIEZXIi70j5B1CsV3fK+8IiKgiqojvBaPi4wgRERERKT0mRERERKT0mBARERGR0mNCREREREqPCREREREpPSZEREREpPSYEBEREZHSY0JERERESo8JERERESk9JkRERESk9JgQERERkdJjQkRERERKjwkRERERKT0mRERERKT0lCohWr16NaysrKClpYXmzZvjzJkz8g6JiIiIFIDSJETbt2/H+PHjMXPmTJw/fx4NGjSAu7s7Hj9+LO/QiIiISM6UJiFasmQJhg8fjiFDhqBu3bpYt24dtLW1ERoaKu/QiIiISM7U5B1AecjOzsa5c+cwZcoUsUxFRQUdO3ZEXFxcgfpZWVnIysoS19PT0wEAUqm0TOLLzMkpk3bLUkZurrxDICKiL0hZfMfmtykIwifrKkVC9N9//yE3NxcmJiYy5SYmJrhx40aB+sHBwZg1a1aBcgsLizKLsaKZJu8AiIjoy2JgUGZNv3jxAgafaF8pEqLimjJlCsaPHy+u5+Xl4dmzZ6hSpQokEkmpHksqlcLCwgIPHjyAvr5+qbatDHj+Pg/P3+fh+fs8PH+fh+fv0wRBwIsXL2Bubv7JukqREFWtWhWqqqp49OiRTPmjR49gampaoL6mpiY0NTVlygwNDcsyROjr6/M/9Gfg+fs8PH+fh+fv8/D8fR6ev4/71MhQPqWYVK2hoYHGjRsjOjpaLMvLy0N0dDRcXFzkGBkREREpAqUYIQKA8ePHw8fHB02aNEGzZs2wbNkyvHz5EkOGDJF3aERERCRnSpMQ9evXD0+ePMGMGTOQmpoKZ2dnHDhwoMBE6/KmqamJmTNnFrhER0XD8/d5eP4+D8/f5+H5+zw8f6VLIhTlXjQiIiKiL5hSzCEiIiIi+hgmRERERKT0mBARERGR0mNCREREREqPCZEcrV69GlZWVtDS0kLz5s1x5swZeYekEIKDg9G0aVPo6enB2NgYPXr0wM2bN2XqZGZmwt/fH1WqVIGuri48PT0LPHgzOTkZXbt2hba2NoyNjTFx4kS8efOmPLsid/Pnz4dEIkFAQIBYxnP3af/++y8GDhyIKlWqoFKlSnB0dER8fLy4XRAEzJgxA2ZmZqhUqRI6duyIxMREmTaePXsGb29v6Ovrw9DQEH5+fsjIyCjvrpS73NxcTJ8+HdbW1qhUqRJq166NOXPmyLxLiufvf44ePYpu3brB3NwcEokEe/fuldleWufq0qVLaNOmDbS0tGBhYYGFCxeWddcqHoHkYtu2bYKGhoYQGhoqXL16VRg+fLhgaGgoPHr0SN6hyZ27u7sQFhYmXLlyRUhISBC++uoroWbNmkJGRoZY57vvvhMsLCyE6OhoIT4+XmjRooXQsmVLcfubN2+E+vXrCx07dhQuXLgg/Pnnn0LVqlWFKVOmyKNLcnHmzBnByspKcHJyEsaOHSuW89x93LNnzwRLS0vB19dXOH36tHD37l3h77//Fm7fvi3WmT9/vmBgYCDs3btXuHjxotC9e3fB2tpaeP36tVjHw8NDaNCggXDq1Cnh2LFjgo2NjeDl5SWPLpWruXPnClWqVBEiIyOFpKQkYefOnYKurq6wfPlysQ7P3//8+eefwtSpU4Xdu3cLAIQ9e/bIbC+Nc5Weni6YmJgI3t7ewpUrV4StW7cKlSpVEtavX19e3awQmBDJSbNmzQR/f39xPTc3VzA3NxeCg4PlGJVievz4sQBAiI2NFQRBENLS0gR1dXVh586dYp3r168LAIS4uDhBEN5+yKioqAipqalinbVr1wr6+vpCVlZW+XZADl68eCHY2toKUVFRQrt27cSEiOfu0yZPniy0bt36g9vz8vIEU1NTYdGiRWJZWlqaoKmpKWzdulUQBEG4du2aAEA4e/asWOevv/4SJBKJ8O+//5Zd8Aqga9euwtChQ2XKevXqJXh7ewuCwPP3Me8nRKV1rtasWSNUrlxZ5vd38uTJgr29fRn3qGLhJTM5yM7Oxrlz59CxY0exTEVFBR07dkRcXJwcI1NM6enpAAAjIyMAwLlz55CTkyNz/hwcHFCzZk3x/MXFxcHR0VHmwZvu7u6QSqW4evVqOUYvH/7+/ujatavMOQJ47opi3759aNKkCfr06QNjY2M0bNgQGzZsELcnJSUhNTVV5hwaGBigefPmMufQ0NAQTZo0Eet07NgRKioqOH36dPl1Rg5atmyJ6Oho3Lp1CwBw8eJFHD9+HF26dAHA81ccpXWu4uLi0LZtW2hoaIh13N3dcfPmTTx//ryceqP4lOZJ1Yrkv//+Q25uboGnZJuYmODGjRtyikox5eXlISAgAK1atUL9+vUBAKmpqdDQ0Cjwwl0TExOkpqaKdQo7v/nbvmTbtm3D+fPncfbs2QLbeO4+7e7du1i7di3Gjx+PH3/8EWfPnsWYMWOgoaEBHx8f8RwUdo7ePYfGxsYy29XU1GBkZPTFn8MffvgBUqkUDg4OUFVVRW5uLubOnQtvb28A4PkrhtI6V6mpqbC2ti7QRv62ypUrl0n8FQ0TIlJo/v7+uHLlCo4fPy7vUCqEBw8eYOzYsYiKioKWlpa8w6mQ8vLy0KRJE8ybNw8A0LBhQ1y5cgXr1q2Dj4+PnKNTfDt27MDmzZuxZcsW1KtXDwkJCQgICIC5uTnPHyk0XjKTg6pVq0JVVbXAnT2PHj2CqampnKJSPKNGjUJkZCSOHDmCGjVqiOWmpqbIzs5GWlqaTP13z5+pqWmh5zd/25fq3LlzePz4MRo1agQ1NTWoqakhNjYWK1asgJqaGkxMTHjuPsHMzAx169aVKatTpw6Sk5MB/O8cfOz319TUFI8fP5bZ/ubNGzx79uyLP4cTJ07EDz/8gP79+8PR0RGDBg3CuHHjEBwcDIDnrzhK61wp++90UTEhkgMNDQ00btwY0dHRYlleXh6io6Ph4uIix8gUgyAIGDVqFPbs2YPDhw8XGOpt3Lgx1NXVZc7fzZs3kZycLJ4/FxcXXL58WeaDIioqCvr6+gW+7L4kHTp0wOXLl5GQkCAuTZo0gbe3t/gzz93HtWrVqsBjHm7dugVLS0sAgLW1NUxNTWXOoVQqxenTp2XOYVpaGs6dOyfWOXz4MPLy8tC8efNy6IX8vHr1Cioqsl8tqqqqyMvLA8DzVxylda5cXFxw9OhR5OTkiHWioqJgb2/Py2XvkvesbmW1bds2QVNTUwgPDxeuXbsmjBgxQjA0NJS5s0dZff/994KBgYEQExMjpKSkiMurV6/EOt99951Qs2ZN4fDhw0J8fLzg4uIiuLi4iNvzbx3v3LmzkJCQIBw4cECoVq2a0tw6/q537zITBJ67Tzlz5oygpqYmzJ07V0hMTBQ2b94saGtrC5s2bRLrzJ8/XzA0NBR+//134dKlS8I333xT6K3QDRs2FE6fPi0cP35csLW1/SJvG3+fj4+PUL16dfG2+927dwtVq1YVJk2aJNbh+fufFy9eCBcuXBAuXLggABCWLFkiXLhwQbh//74gCKVzrtLS0gQTExNh0KBBwpUrV4Rt27YJ2travO3+PUyI5GjlypVCzZo1BQ0NDaFZs2bCqVOn5B2SQgBQ6BIWFibWef36tTBy5EihcuXKgra2ttCzZ08hJSVFpp179+4JXbp0ESpVqiRUrVpVCAwMFHJycsq5N/L3fkLEc/dpf/zxh1C/fn1BU1NTcHBwEH755ReZ7Xl5ecL06dMFExMTQVNTU+jQoYNw8+ZNmTpPnz4VvLy8BF1dXUFfX18YMmSI8OLFi/LshlxIpVJh7NixQs2aNQUtLS2hVq1awtSpU2Vu+eb5+58jR44U+nnn4+MjCELpnauLFy8KrVu3FjQ1NYXq1asL8+fPL68uVhgSQXjn8aFERERESohziIiIiEjpMSEiIiIipceEiIiIiJQeEyIiIiJSekyIiIiISOkxISIiIiKlx4SIiIiIlB4TIiIiIlJ6TIiIiIhI6TEhIiIiIqXHhIiIiIiUHhMiIiIiUnr/DyOMBuLos8GCAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'no'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m label_encoder \u001b[38;5;241m=\u001b[39m LabelEncoder()\n\u001b[0;32m      3\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGender\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m label_encoder\u001b[38;5;241m.\u001b[39mfit_transform(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGender\u001b[39m\u001b[38;5;124m'\u001b[39m])  \n\u001b[1;32m----> 5\u001b[0m correlations \u001b[38;5;241m=\u001b[39m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcorr\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# plot correlation matrix\u001b[39;00m\n\u001b[0;32m      8\u001b[0m myfig \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39mfigure()\n",
      "File \u001b[1;32mc:\\Users\\elahehba\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py:11049\u001b[0m, in \u001b[0;36mDataFrame.corr\u001b[1;34m(self, method, min_periods, numeric_only)\u001b[0m\n\u001b[0;32m  11047\u001b[0m cols \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[0;32m  11048\u001b[0m idx \u001b[38;5;241m=\u001b[39m cols\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m> 11049\u001b[0m mat \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnan\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m  11051\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpearson\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m  11052\u001b[0m     correl \u001b[38;5;241m=\u001b[39m libalgos\u001b[38;5;241m.\u001b[39mnancorr(mat, minp\u001b[38;5;241m=\u001b[39mmin_periods)\n",
      "File \u001b[1;32mc:\\Users\\elahehba\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py:1993\u001b[0m, in \u001b[0;36mDataFrame.to_numpy\u001b[1;34m(self, dtype, copy, na_value)\u001b[0m\n\u001b[0;32m   1991\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1992\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdtype(dtype)\n\u001b[1;32m-> 1993\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1994\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m dtype:\n\u001b[0;32m   1995\u001b[0m     result \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(result, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "File \u001b[1;32mc:\\Users\\elahehba\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1694\u001b[0m, in \u001b[0;36mBlockManager.as_array\u001b[1;34m(self, dtype, copy, na_value)\u001b[0m\n\u001b[0;32m   1692\u001b[0m         arr\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mwriteable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1693\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1694\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interleave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1695\u001b[0m     \u001b[38;5;66;03m# The underlying data was copied within _interleave, so no need\u001b[39;00m\n\u001b[0;32m   1696\u001b[0m     \u001b[38;5;66;03m# to further copy if copy=True or setting na_value\u001b[39;00m\n\u001b[0;32m   1698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_value \u001b[38;5;129;01mis\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n",
      "File \u001b[1;32mc:\\Users\\elahehba\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1753\u001b[0m, in \u001b[0;36mBlockManager._interleave\u001b[1;34m(self, dtype, na_value)\u001b[0m\n\u001b[0;32m   1751\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1752\u001b[0m         arr \u001b[38;5;241m=\u001b[39m blk\u001b[38;5;241m.\u001b[39mget_values(dtype)\n\u001b[1;32m-> 1753\u001b[0m     \u001b[43mresult\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindexer\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m arr\n\u001b[0;32m   1754\u001b[0m     itemmask[rl\u001b[38;5;241m.\u001b[39mindexer] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1756\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m itemmask\u001b[38;5;241m.\u001b[39mall():\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'no'"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "df['Gender'] = label_encoder.fit_transform(df['Gender'])  \n",
    "\n",
    "correlations =df.corr()\n",
    "# plot correlation matrix\n",
    "\n",
    "myfig = plt.figure()\n",
    "axis = myfig.add_subplot(111) # There is only one subplot or graph;\n",
    "# \"111\" means \"1x1 grid, first subplot\"\n",
    "\n",
    "cax = axis.matshow(correlations, vmin =-1, vmax = 1)\n",
    "myfig.colorbar(cax)\n",
    "ticks = np.arange(0, 17, 1) # np.arange(start, stop, step); the interval does not include stop value\n",
    "\n",
    "axis.set_xticks(ticks)\n",
    "axis.set_yticks(ticks)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'no'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m Y \u001b[38;5;241m=\u001b[39m data[:,\u001b[38;5;241m16\u001b[39m]\n\u001b[0;32m      7\u001b[0m mydataScaler \u001b[38;5;241m=\u001b[39m MinMaxScaler(feature_range \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m----> 8\u001b[0m mydataRescaled \u001b[38;5;241m=\u001b[39m \u001b[43mmydataScaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m set_printoptions(precision \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(mydataRescaled[\u001b[38;5;241m20\u001b[39m:\u001b[38;5;241m25\u001b[39m,:])\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\_set_output.py:316\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    314\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    315\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 316\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    317\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    318\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    319\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    320\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    321\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    322\u001b[0m         )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\base.py:1098\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m   1083\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1084\u001b[0m             (\n\u001b[0;32m   1085\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis object (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) has a `transform`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1093\u001b[0m             \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[0;32m   1094\u001b[0m         )\n\u001b[0;32m   1096\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1097\u001b[0m     \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[1;32m-> 1098\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1100\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[0;32m   1101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\preprocessing\\_data.py:450\u001b[0m, in \u001b[0;36mMinMaxScaler.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;66;03m# Reset internal state before fitting\u001b[39;00m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[1;32m--> 450\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpartial_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\preprocessing\\_data.py:490\u001b[0m, in \u001b[0;36mMinMaxScaler.partial_fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    487\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[0;32m    489\u001b[0m first_pass \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_samples_seen_\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 490\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    492\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfirst_pass\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_array_api\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msupported_float_dtypes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    495\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    497\u001b[0m data_min \u001b[38;5;241m=\u001b[39m _array_api\u001b[38;5;241m.\u001b[39m_nanmin(X, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, xp\u001b[38;5;241m=\u001b[39mxp)\n\u001b[0;32m    498\u001b[0m data_max \u001b[38;5;241m=\u001b[39m _array_api\u001b[38;5;241m.\u001b[39m_nanmax(X, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, xp\u001b[38;5;241m=\u001b[39mxp)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\base.py:633\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    631\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 633\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    634\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[0;32m    635\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:1012\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m   1010\u001b[0m         array \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(array, dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1011\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1012\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43m_asarray_with_order\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1013\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[0;32m   1014\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1015\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[0;32m   1016\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\_array_api.py:745\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[1;34m(array, dtype, order, copy, xp, device)\u001b[0m\n\u001b[0;32m    743\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39marray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 745\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[0;32m    748\u001b[0m \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n\u001b[0;32m    749\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(array)\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'no'"
     ]
    }
   ],
   "source": [
    "from numpy import set_printoptions\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "data = df.values\n",
    "X = data[:,0:16]\n",
    "Y = data[:,16]\n",
    "mydataScaler = MinMaxScaler(feature_range = (0, 1))\n",
    "mydataRescaled = mydataScaler.fit_transform(X)\n",
    "set_printoptions(precision = 3)\n",
    "print(mydataRescaled[20:25,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'no'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m mydata_train\u001b[38;5;241m=\u001b[39mdata[:,\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m16\u001b[39m]\n\u001b[0;32m      5\u001b[0m mydata_label\u001b[38;5;241m=\u001b[39mdata[:,\u001b[38;5;241m16\u001b[39m]\n\u001b[1;32m----> 6\u001b[0m mydataScaler\u001b[38;5;241m=\u001b[39m\u001b[43mNormalizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmydata_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m mydataNormalized\u001b[38;5;241m=\u001b[39mmydataScaler\u001b[38;5;241m.\u001b[39mtransform(mydata_train)\n\u001b[0;32m      8\u001b[0m set_printoptions(precision\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\preprocessing\\_data.py:2082\u001b[0m, in \u001b[0;36mNormalizer.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m   2062\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   2063\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   2064\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Only validates estimator's parameters.\u001b[39;00m\n\u001b[0;32m   2065\u001b[0m \n\u001b[0;32m   2066\u001b[0m \u001b[38;5;124;03m    This method allows to: (i) validate the estimator's parameters and\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2080\u001b[0m \u001b[38;5;124;03m        Fitted transformer.\u001b[39;00m\n\u001b[0;32m   2081\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2082\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2083\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\base.py:633\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    631\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 633\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    634\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[0;32m    635\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:1012\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m   1010\u001b[0m         array \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(array, dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1011\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1012\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43m_asarray_with_order\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1013\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[0;32m   1014\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1015\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[0;32m   1016\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\_array_api.py:745\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[1;34m(array, dtype, order, copy, xp, device)\u001b[0m\n\u001b[0;32m    743\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39marray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 745\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[0;32m    748\u001b[0m \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n\u001b[0;32m    749\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(array)\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'no'"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "from numpy import set_printoptions\n",
    "\n",
    "mydata_train=data[:,0:16]\n",
    "mydata_label=data[:,16]\n",
    "mydataScaler=Normalizer().fit(mydata_train)\n",
    "mydataNormalized=mydataScaler.transform(mydata_train)\n",
    "set_printoptions(precision=3)\n",
    "print(mydataNormalized[20:25,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 0. 0. 1. 1. 1.]\n",
      " [0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 1.]\n",
      " [1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 0. 0. 0. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import Binarizer\n",
    "\n",
    "mydata_train=data[:,0:16]\n",
    "mydata_label=data[:,16]\n",
    "mydataBinarizer=Binarizer(threshold=0.0).fit(mydata_train)\n",
    "mydatabinarized=mydataBinarizer.transform(mydata_train)\n",
    "set_printoptions(precision=3)\n",
    "print(mydatabinarized[0:5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.250e+02 6.356e+02 1.066e+00 1.419e+04 1.134e+02 2.708e+01 6.032e+01\n",
      " 3.378e+01 4.679e+01 3.147e+01 1.740e+01 1.174e+02 7.176e+01 2.613e+01\n",
      " 2.182e+01 1.028e+02]\n"
     ]
    }
   ],
   "source": [
    "from numpy import set_printoptions\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "data=df.values\n",
    "mydata_train=data[:,0:16]\n",
    "mydata_label=data[:,16]\n",
    "#featureextraction\n",
    "myFeature=SelectKBest(score_func=chi2,k=4) #kisnumberoftopfeaturestoselect\n",
    "fit=myFeature.fit(mydata_train,mydata_label)\n",
    "#summarizescores\n",
    "set_printoptions(precision=3)\n",
    "print(fit.scores_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elahehba\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\elahehba\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\elahehba\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\elahehba\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\elahehba\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\elahehba\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\elahehba\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\elahehba\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\elahehba\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\elahehba\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\elahehba\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numberoffeatures:3\n",
      "SelectedfeaturesaredenotedbyTrue:[ True False  True False False False  True False False False False False\n",
      " False False False False]\n",
      "FeatureRanking:[ 1 12  1 11  2  3  1  6  4 14  9 13 10  8  5  7]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elahehba\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\elahehba\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\elahehba\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "data=df.values\n",
    "\n",
    "mydata_train= data[:,0:16]\n",
    "mydata_label= data[:,16]\n",
    "# featureextraction\n",
    "model=LogisticRegression()\n",
    "mydataRFE= RFE(model,n_features_to_select=3)\n",
    "mydataFit=mydataRFE.fit(mydata_train,mydata_label)\n",
    "print(\"Numberoffeatures:%d\" %mydataFit.n_features_)\n",
    "print(\"SelectedfeaturesaredenotedbyTrue:%s\"%mydataFit.support_)\n",
    "print(\"FeatureRanking:%s\" %mydataFit.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained Variance: [0.941 0.054 0.001]\n",
      "[[ 3.087e-03  5.193e-02  1.642e-03  9.986e-01  7.337e-03  3.328e-03\n",
      "   4.394e-03  3.166e-03  5.143e-03  1.462e-04  4.665e-03 -1.612e-03\n",
      "  -1.724e-03 -1.745e-03 -4.064e-03 -1.444e-04]\n",
      " [ 1.337e-03  9.899e-01 -1.866e-03 -5.156e-02  6.303e-03  3.786e-04\n",
      "  -2.735e-03 -8.377e-03  1.771e-03  1.986e-03 -8.927e-03 -2.482e-03\n",
      "  -1.868e-02 -2.820e-02  7.560e-06 -1.272e-01]\n",
      " [-1.390e-01  1.042e-01 -3.046e-02 -4.344e-03 -2.002e-02 -1.435e-02\n",
      "   4.375e-02 -2.546e-01 -1.016e-02  5.624e-03 -6.440e-02 -2.510e-03\n",
      "  -3.379e-01 -1.766e-02 -1.891e-02  8.845e-01]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# featureextraction\n",
    "pca=PCA(n_components=3)\n",
    "fit=pca.fit(mydata_train)\n",
    "print(\"Explained Variance: %s\" % fit.explained_variance_ratio_)\n",
    "print(fit.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2111, 1)\n"
     ]
    }
   ],
   "source": [
    "pca=PCA(0.92)\n",
    "selectedFeatures = pca.fit_transform(mydata_train)\n",
    "print(selectedFeatures.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.088 0.077 0.079 0.277 0.044 0.025 0.074 0.057 0.038 0.004 0.044 0.012\n",
      " 0.042 0.046 0.055 0.038]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "# feature extraction\n",
    "model = ExtraTreesClassifier()\n",
    "model.fit(mydata_train, mydata_label)\n",
    "print(model.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\elahehba\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3481 - loss: 1.7593 - val_accuracy: 0.6243 - val_loss: 1.1732\n",
      "Epoch 2/100\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6403 - loss: 1.0968 - val_accuracy: 0.7041 - val_loss: 0.8328\n",
      "Epoch 3/100\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7269 - loss: 0.7987 - val_accuracy: 0.7811 - val_loss: 0.6389\n",
      "Epoch 4/100\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8071 - loss: 0.6018 - val_accuracy: 0.8107 - val_loss: 0.5369\n",
      "Epoch 5/100\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8553 - loss: 0.4622 - val_accuracy: 0.8402 - val_loss: 0.4408\n",
      "Epoch 6/100\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8697 - loss: 0.3782 - val_accuracy: 0.8905 - val_loss: 0.3699\n",
      "Epoch 7/100\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9016 - loss: 0.3210 - val_accuracy: 0.8964 - val_loss: 0.3327\n",
      "Epoch 8/100\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9320 - loss: 0.2807 - val_accuracy: 0.9112 - val_loss: 0.2832\n",
      "Epoch 9/100\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9441 - loss: 0.2318 - val_accuracy: 0.9320 - val_loss: 0.2505\n",
      "Epoch 10/100\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9593 - loss: 0.2013 - val_accuracy: 0.9379 - val_loss: 0.2242\n",
      "Epoch 11/100\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9492 - loss: 0.1876 - val_accuracy: 0.9438 - val_loss: 0.2072\n",
      "Epoch 12/100\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9773 - loss: 0.1401 - val_accuracy: 0.9379 - val_loss: 0.1917\n",
      "Epoch 13/100\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9802 - loss: 0.1266 - val_accuracy: 0.9586 - val_loss: 0.1775\n",
      "Epoch 14/100\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9855 - loss: 0.1112 - val_accuracy: 0.9379 - val_loss: 0.1716\n",
      "Epoch 15/100\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9890 - loss: 0.1012 - val_accuracy: 0.9497 - val_loss: 0.1505\n",
      "Epoch 16/100\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9912 - loss: 0.0795 - val_accuracy: 0.9408 - val_loss: 0.1548\n",
      "Epoch 17/100\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9915 - loss: 0.0772 - val_accuracy: 0.9586 - val_loss: 0.1424\n",
      "Epoch 18/100\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9930 - loss: 0.0562 - val_accuracy: 0.9497 - val_loss: 0.1294\n",
      "Epoch 19/100\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9960 - loss: 0.0601 - val_accuracy: 0.9497 - val_loss: 0.1294\n",
      "Epoch 20/100\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9997 - loss: 0.0470 - val_accuracy: 0.9467 - val_loss: 0.1359\n",
      "Epoch 21/100\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9959 - loss: 0.0399 - val_accuracy: 0.9527 - val_loss: 0.1281\n",
      "Epoch 22/100\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9980 - loss: 0.0384 - val_accuracy: 0.9615 - val_loss: 0.1221\n",
      "Epoch 23/100\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 0.0344 - val_accuracy: 0.9556 - val_loss: 0.1227\n",
      "Epoch 24/100\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9990 - loss: 0.0337 - val_accuracy: 0.9497 - val_loss: 0.1200\n",
      "Epoch 25/100\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9985 - loss: 0.0281 - val_accuracy: 0.9527 - val_loss: 0.1229\n",
      "Epoch 26/100\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9978 - loss: 0.0258 - val_accuracy: 0.9467 - val_loss: 0.1236\n",
      "Epoch 27/100\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9993 - loss: 0.0212 - val_accuracy: 0.9527 - val_loss: 0.1210\n",
      "Epoch 28/100\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9997 - loss: 0.0181 - val_accuracy: 0.9556 - val_loss: 0.1237\n",
      "Epoch 29/100\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0159 - val_accuracy: 0.9467 - val_loss: 0.1263\n",
      "Epoch 30/100\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0161 - val_accuracy: 0.9586 - val_loss: 0.1159\n",
      "Epoch 31/100\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0138 - val_accuracy: 0.9586 - val_loss: 0.1212\n",
      "Epoch 32/100\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0111 - val_accuracy: 0.9467 - val_loss: 0.1250\n",
      "Epoch 33/100\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0116 - val_accuracy: 0.9645 - val_loss: 0.1250\n",
      "Epoch 34/100\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9999 - loss: 0.0102 - val_accuracy: 0.9527 - val_loss: 0.1308\n",
      "Epoch 35/100\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9981 - loss: 0.0116 - val_accuracy: 0.9497 - val_loss: 0.1348\n",
      "Epoch 36/100\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0092 - val_accuracy: 0.9586 - val_loss: 0.1289\n",
      "Epoch 37/100\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0093 - val_accuracy: 0.9438 - val_loss: 0.1353\n",
      "Epoch 38/100\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0073 - val_accuracy: 0.9586 - val_loss: 0.1253\n",
      "Epoch 39/100\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0069 - val_accuracy: 0.9467 - val_loss: 0.1300\n",
      "Epoch 40/100\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0056 - val_accuracy: 0.9527 - val_loss: 0.1359\n",
      "Epoch 41/100\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0048 - val_accuracy: 0.9527 - val_loss: 0.1286\n",
      "Epoch 42/100\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0045 - val_accuracy: 0.9527 - val_loss: 0.1277\n",
      "Epoch 43/100\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0039 - val_accuracy: 0.9556 - val_loss: 0.1406\n",
      "Epoch 44/100\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0038 - val_accuracy: 0.9556 - val_loss: 0.1355\n",
      "Epoch 45/100\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0033 - val_accuracy: 0.9467 - val_loss: 0.1475\n",
      "Epoch 46/100\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0029 - val_accuracy: 0.9527 - val_loss: 0.1380\n",
      "Epoch 47/100\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0030 - val_accuracy: 0.9497 - val_loss: 0.1451\n",
      "Epoch 48/100\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0025 - val_accuracy: 0.9497 - val_loss: 0.1431\n",
      "Epoch 49/100\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0025 - val_accuracy: 0.9527 - val_loss: 0.1445\n",
      "Epoch 50/100\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0023 - val_accuracy: 0.9467 - val_loss: 0.1464\n",
      "Epoch 51/100\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.9556 - val_loss: 0.1428\n",
      "Epoch 52/100\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.9527 - val_loss: 0.1473\n",
      "Epoch 53/100\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.9556 - val_loss: 0.1515\n",
      "Epoch 54/100\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.9527 - val_loss: 0.1540\n",
      "Epoch 55/100\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.9527 - val_loss: 0.1516\n",
      "Epoch 56/100\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.9527 - val_loss: 0.1544\n",
      "Epoch 57/100\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.9527 - val_loss: 0.1535\n",
      "Epoch 58/100\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.9497 - val_loss: 0.1782\n",
      "Epoch 59/100\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9980 - loss: 0.0075 - val_accuracy: 0.9467 - val_loss: 0.1834\n",
      "Epoch 60/100\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9989 - loss: 0.0044 - val_accuracy: 0.9467 - val_loss: 0.2041\n",
      "Epoch 61/100\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9916 - loss: 0.0179 - val_accuracy: 0.9586 - val_loss: 0.1496\n",
      "Epoch 62/100\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0028 - val_accuracy: 0.9497 - val_loss: 0.1621\n",
      "Epoch 63/100\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.9497 - val_loss: 0.1691\n",
      "Epoch 64/100\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.1058e-04 - val_accuracy: 0.9556 - val_loss: 0.1727\n",
      "Epoch 65/100\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.4650e-04 - val_accuracy: 0.9527 - val_loss: 0.1730\n",
      "Epoch 66/100\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.6684e-04 - val_accuracy: 0.9527 - val_loss: 0.1749\n",
      "Epoch 67/100\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.1863e-04 - val_accuracy: 0.9527 - val_loss: 0.1738\n",
      "Epoch 68/100\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.5130e-04 - val_accuracy: 0.9527 - val_loss: 0.1770\n",
      "Epoch 69/100\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 6.5010e-04 - val_accuracy: 0.9527 - val_loss: 0.1773\n",
      "Epoch 70/100\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 5.6164e-04 - val_accuracy: 0.9527 - val_loss: 0.1808\n",
      "Epoch 71/100\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 6.1229e-04 - val_accuracy: 0.9497 - val_loss: 0.1842\n",
      "Epoch 72/100\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.7103e-04 - val_accuracy: 0.9497 - val_loss: 0.1827\n",
      "Epoch 73/100\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.1501e-04 - val_accuracy: 0.9497 - val_loss: 0.1842\n",
      "Epoch 74/100\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.7838e-04 - val_accuracy: 0.9527 - val_loss: 0.1843\n",
      "Epoch 75/100\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.4096e-04 - val_accuracy: 0.9527 - val_loss: 0.1820\n",
      "Epoch 76/100\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.9420e-04 - val_accuracy: 0.9527 - val_loss: 0.1892\n",
      "Epoch 77/100\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.6855e-04 - val_accuracy: 0.9527 - val_loss: 0.1865\n",
      "Epoch 78/100\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.7711e-04 - val_accuracy: 0.9467 - val_loss: 0.1872\n",
      "Epoch 79/100\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.4954e-04 - val_accuracy: 0.9556 - val_loss: 0.1836\n",
      "Epoch 80/100\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.6091e-04 - val_accuracy: 0.9527 - val_loss: 0.1892\n",
      "Epoch 81/100\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.8972e-04 - val_accuracy: 0.9527 - val_loss: 0.1873\n",
      "Epoch 82/100\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.0021e-04 - val_accuracy: 0.9527 - val_loss: 0.1906\n",
      "Epoch 83/100\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.8266e-04 - val_accuracy: 0.9497 - val_loss: 0.1927\n",
      "Epoch 84/100\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.4099e-04 - val_accuracy: 0.9497 - val_loss: 0.1955\n",
      "Epoch 85/100\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.3214e-04 - val_accuracy: 0.9497 - val_loss: 0.1906\n",
      "Epoch 86/100\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.6174e-04 - val_accuracy: 0.9497 - val_loss: 0.1936\n",
      "Epoch 87/100\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.2503e-04 - val_accuracy: 0.9497 - val_loss: 0.1948\n",
      "Epoch 88/100\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.2286e-04 - val_accuracy: 0.9467 - val_loss: 0.1994\n",
      "Epoch 89/100\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.0657e-04 - val_accuracy: 0.9467 - val_loss: 0.2019\n",
      "Epoch 90/100\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.1272e-04 - val_accuracy: 0.9527 - val_loss: 0.1998\n",
      "Epoch 91/100\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.7592e-04 - val_accuracy: 0.9497 - val_loss: 0.2027\n",
      "Epoch 92/100\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6060e-04 - val_accuracy: 0.9527 - val_loss: 0.1986\n",
      "Epoch 93/100\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.5504e-04 - val_accuracy: 0.9497 - val_loss: 0.2034\n",
      "Epoch 94/100\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3508e-04 - val_accuracy: 0.9527 - val_loss: 0.2028\n",
      "Epoch 95/100\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.5699e-04 - val_accuracy: 0.9527 - val_loss: 0.2090\n",
      "Epoch 96/100\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2350e-04 - val_accuracy: 0.9497 - val_loss: 0.2079\n",
      "Epoch 97/100\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2377e-04 - val_accuracy: 0.9497 - val_loss: 0.2072\n",
      "Epoch 98/100\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2192e-04 - val_accuracy: 0.9527 - val_loss: 0.2092\n",
      "Epoch 99/100\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0850e-04 - val_accuracy: 0.9497 - val_loss: 0.2113\n",
      "Epoch 100/100\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.5142e-05 - val_accuracy: 0.9497 - val_loss: 0.2119\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "دقت مدل: 0.9479905437352246\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "label_encoders = {}\n",
    "categorical_columns = ['Gender', 'family_history_with_overweight', 'FAVC', 'CAEC', 'SMOKE', 'SCC', 'CALC', 'MTRANS', 'NObeyesdad']\n",
    "\n",
    "for column in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    df[column] = le.fit_transform(df[column])\n",
    "    label_encoders[column] = le\n",
    "\n",
    "\n",
    "X = df.drop('NObeyesdad', axis=1)  \n",
    "y = df['NObeyesdad']  \n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_shape=(X_train.shape[1],)))  \n",
    "model.add(Dense(32, activation='relu')) \n",
    "model.add(Dense(len(np.unique(y)), activation='softmax')) \n",
    "\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=10, validation_split=0.2, verbose=1)\n",
    "\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1) \n",
    "\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred_classes)\n",
    "print(\"دقت مدل:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.7943\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == 'object':  \n",
    "        df[col] = encoder.fit_transform(df[col])\n",
    "\n",
    "X = df.drop(columns=['NObeyesdad'])\n",
    "y = df['NObeyesdad']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "pca = PCA(n_components=15)\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "# اعمال مدل KNN\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train_pca, y_train)\n",
    "\n",
    "y_pred = knn.predict(X_test_pca)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy : {accuracy:.4f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9574468085106383\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "for column in X.columns:\n",
    "    if X[column].dtype == 'object':\n",
    "        X[column] = label_encoder.fit_transform(X[column])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# ایجاد و آموزش مدل Random Forest\n",
    "random_forest = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "random_forest.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = random_forest.predict(X_test_scaled)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.933806146572104\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "for column in X.columns:\n",
    "    if X[column].dtype == 'object':\n",
    "        X[column] = label_encoder.fit_transform(X[column])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# ایجاد و آموزش مدل Decision Tree\n",
    "decision_tree = DecisionTreeClassifier(random_state=42)\n",
    "decision_tree.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = decision_tree.predict(X_test_scaled)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8794326241134752\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "for column in X.columns:\n",
    "    if X[column].dtype == 'object':\n",
    "        X[column] = label_encoder.fit_transform(X[column])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# ایجاد و آموزش مدل Logistic Regression\n",
    "logistic_model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "logistic_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = logistic_model.predict(X_test_scaled)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8841607565011821\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "for column in X.columns:\n",
    "    if X[column].dtype == 'object':\n",
    "        X[column] = label_encoder.fit_transform(X[column])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# ایجاد و آموزش مدل SVM\n",
    "svm_model = SVC(kernel='rbf', random_state=42) \n",
    "svm_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = svm_model.predict(X_test_scaled)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
